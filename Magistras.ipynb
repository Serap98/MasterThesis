{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFQV3ffSb99d",
        "outputId": "f080d187-fa44-42d6-8619-4408a1320401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "\n",
        "os.getcwd()\n",
        "os.chdir('gdrive/MyDrive')"
      ],
      "metadata": {
        "id": "JYuGvXDLckda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07yw9bWjeqYe",
        "outputId": "110e12d8-eb63-44b5-d448-bce0d65b3384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Extracting zip file\n",
        "import zipfile\n",
        "\n",
        "zip_folder = Path(\"univariate_time_series/Univariate2018_arff.zip\")\n",
        "extracted_zip_folder = \"extracted_univariate_time_series\"\n",
        "\n",
        "with zipfile.ZipFile(zip_folder, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_zip_folder)\"\"\""
      ],
      "metadata": {
        "id": "Ymzw4Ou8wdii",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "eecbd59c-00e3-4672-ec30-6652db0c9571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Extracting zip file\\nimport zipfile\\n\\nzip_folder = Path(\"univariate_time_series/Univariate2018_arff.zip\")\\nextracted_zip_folder = \"extracted_univariate_time_series\"\\n\\nwith zipfile.ZipFile(zip_folder, \\'r\\') as zip_ref:\\n    zip_ref.extractall(extracted_zip_folder)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# \n",
        "extracted_zip_folder = \"extracted_univariate_time_series\"\n",
        "folders = os.listdir(f\"{extracted_zip_folder}/Univariate_arff\")\n",
        "folder = folders[0]"
      ],
      "metadata": {
        "id": "DfGVVCp36-ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.listdir(f\"{extracted_zip_folder}/Univariate_arff/{folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjdMwaM0-_7r",
        "outputId": "b53e4ef7-4494-4cbf-c674-dad35d0dd16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ACSF1.txt',\n",
              " 'ACSF1_TEST.arff',\n",
              " 'ACSF1_TEST.txt',\n",
              " 'ACSF1_TRAIN.arff',\n",
              " 'ACSF1_TRAIN.txt',\n",
              " 'README.md']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(folders)\n",
        "sample_files = f\"{extracted_zip_folder}/Univariate_arff/{folder}/ACSF1_TRAIN.arff\""
      ],
      "metadata": {
        "id": "luN_ppzb_Mek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "\n",
        "data = arff.loadarff(sample_files)\n",
        "df = pd.DataFrame(data[0])\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "EgBOnnUi_gkH",
        "outputId": "196aca16-f4ec-46f4-a619-35e4b66efec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        att1      att2      att3      att4      att5      att6      att7  \\\n",
              "0  -0.584754 -0.584754  1.730991 -0.584754 -0.584754 -0.584754  1.729917   \n",
              "1  -0.591434 -0.511104  1.726820 -0.580422 -0.591434 -0.511104  1.727921   \n",
              "2  -0.577945 -0.577945  1.730793 -0.577945 -0.578946 -0.564882  1.731094   \n",
              "3  -0.588925 -0.538088  1.735718 -0.588716 -0.589962 -0.523551  1.735619   \n",
              "4  -0.596633 -0.532188  1.718067 -0.592117 -0.596633 -0.532188  1.715241   \n",
              "..       ...       ...       ...       ...       ...       ...       ...   \n",
              "95 -0.706092 -0.706092  1.619903 -0.706092 -0.706092 -0.706092  1.610364   \n",
              "96 -0.634760 -0.634760  1.584916 -0.634760 -0.634760 -0.634760  1.581811   \n",
              "97 -0.998277  0.102462  1.606925 -0.692702 -0.998277  0.104508  1.607083   \n",
              "98 -0.941473  0.587214  1.523644 -0.645350 -0.938475  0.585218  1.530411   \n",
              "99 -0.661536 -0.661536  1.510327 -0.661536 -0.661536 -0.661536  1.473648   \n",
              "\n",
              "        att8      att9     att10  ...   att1452   att1453   att1454   att1455  \\\n",
              "0  -0.584754 -0.584754 -0.584754  ... -0.584734 -0.583729 -0.578603  1.732726   \n",
              "1  -0.580422 -0.591434 -0.511104  ... -0.580731 -0.580731 -0.580731  1.727396   \n",
              "2  -0.577829 -0.580956 -0.548788  ... -0.577751 -0.580956 -0.549798  1.734727   \n",
              "3  -0.588646 -0.588925 -0.524598  ... -0.588876 -0.586852 -0.576483  1.743664   \n",
              "4  -0.592117 -0.595605 -0.532188  ... -0.592403 -0.591524 -0.575158  1.743258   \n",
              "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
              "95 -0.706092 -0.706092 -0.706092  ... -0.702217 -0.956546  0.122643  1.621752   \n",
              "96 -0.634760 -0.634760 -0.634760  ... -0.631032 -1.039049  0.085802  1.608606   \n",
              "97 -0.692692 -0.999305  0.105525  ... -0.692653 -0.991113  0.099389  1.563691   \n",
              "98 -0.645379 -0.941473  0.587214  ... -0.645292 -1.046250  0.582230  1.548224   \n",
              "99 -0.661536 -0.915802 -0.519394  ... -0.660685 -0.851728 -0.660539  1.510105   \n",
              "\n",
              "     att1456   att1457   att1458   att1459   att1460  target  \n",
              "0  -0.584734 -0.583729 -0.578603  1.732726 -0.584734    b'9'  \n",
              "1  -0.580731 -0.580731 -0.580731  1.727396 -0.580731    b'9'  \n",
              "2  -0.577751 -0.580956 -0.549798  1.734727 -0.577751    b'9'  \n",
              "3  -0.588876 -0.586852 -0.576483  1.743664 -0.588876    b'9'  \n",
              "4  -0.592403 -0.591524 -0.575158  1.743258 -0.592403    b'9'  \n",
              "..       ...       ...       ...       ...       ...     ...  \n",
              "95 -0.702217 -0.956546  0.122643  1.621752 -0.702217    b'1'  \n",
              "96 -0.631032 -1.039049  0.085802  1.608606 -0.631032    b'1'  \n",
              "97 -0.692653 -0.991113  0.099389  1.563691 -0.692653    b'1'  \n",
              "98 -0.645292 -1.046250  0.582230  1.548224 -0.645292    b'1'  \n",
              "99 -0.660685 -0.851728 -0.660539  1.510105 -0.660685    b'1'  \n",
              "\n",
              "[100 rows x 1461 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-489f64b3-5578-4bda-933f-eb24d3f6b1dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>att1</th>\n",
              "      <th>att2</th>\n",
              "      <th>att3</th>\n",
              "      <th>att4</th>\n",
              "      <th>att5</th>\n",
              "      <th>att6</th>\n",
              "      <th>att7</th>\n",
              "      <th>att8</th>\n",
              "      <th>att9</th>\n",
              "      <th>att10</th>\n",
              "      <th>...</th>\n",
              "      <th>att1452</th>\n",
              "      <th>att1453</th>\n",
              "      <th>att1454</th>\n",
              "      <th>att1455</th>\n",
              "      <th>att1456</th>\n",
              "      <th>att1457</th>\n",
              "      <th>att1458</th>\n",
              "      <th>att1459</th>\n",
              "      <th>att1460</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>1.730991</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>1.729917</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.584734</td>\n",
              "      <td>-0.583729</td>\n",
              "      <td>-0.578603</td>\n",
              "      <td>1.732726</td>\n",
              "      <td>-0.584734</td>\n",
              "      <td>-0.583729</td>\n",
              "      <td>-0.578603</td>\n",
              "      <td>1.732726</td>\n",
              "      <td>-0.584734</td>\n",
              "      <td>b'9'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.591434</td>\n",
              "      <td>-0.511104</td>\n",
              "      <td>1.726820</td>\n",
              "      <td>-0.580422</td>\n",
              "      <td>-0.591434</td>\n",
              "      <td>-0.511104</td>\n",
              "      <td>1.727921</td>\n",
              "      <td>-0.580422</td>\n",
              "      <td>-0.591434</td>\n",
              "      <td>-0.511104</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.580731</td>\n",
              "      <td>-0.580731</td>\n",
              "      <td>-0.580731</td>\n",
              "      <td>1.727396</td>\n",
              "      <td>-0.580731</td>\n",
              "      <td>-0.580731</td>\n",
              "      <td>-0.580731</td>\n",
              "      <td>1.727396</td>\n",
              "      <td>-0.580731</td>\n",
              "      <td>b'9'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.577945</td>\n",
              "      <td>-0.577945</td>\n",
              "      <td>1.730793</td>\n",
              "      <td>-0.577945</td>\n",
              "      <td>-0.578946</td>\n",
              "      <td>-0.564882</td>\n",
              "      <td>1.731094</td>\n",
              "      <td>-0.577829</td>\n",
              "      <td>-0.580956</td>\n",
              "      <td>-0.548788</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.577751</td>\n",
              "      <td>-0.580956</td>\n",
              "      <td>-0.549798</td>\n",
              "      <td>1.734727</td>\n",
              "      <td>-0.577751</td>\n",
              "      <td>-0.580956</td>\n",
              "      <td>-0.549798</td>\n",
              "      <td>1.734727</td>\n",
              "      <td>-0.577751</td>\n",
              "      <td>b'9'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.588925</td>\n",
              "      <td>-0.538088</td>\n",
              "      <td>1.735718</td>\n",
              "      <td>-0.588716</td>\n",
              "      <td>-0.589962</td>\n",
              "      <td>-0.523551</td>\n",
              "      <td>1.735619</td>\n",
              "      <td>-0.588646</td>\n",
              "      <td>-0.588925</td>\n",
              "      <td>-0.524598</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.588876</td>\n",
              "      <td>-0.586852</td>\n",
              "      <td>-0.576483</td>\n",
              "      <td>1.743664</td>\n",
              "      <td>-0.588876</td>\n",
              "      <td>-0.586852</td>\n",
              "      <td>-0.576483</td>\n",
              "      <td>1.743664</td>\n",
              "      <td>-0.588876</td>\n",
              "      <td>b'9'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.596633</td>\n",
              "      <td>-0.532188</td>\n",
              "      <td>1.718067</td>\n",
              "      <td>-0.592117</td>\n",
              "      <td>-0.596633</td>\n",
              "      <td>-0.532188</td>\n",
              "      <td>1.715241</td>\n",
              "      <td>-0.592117</td>\n",
              "      <td>-0.595605</td>\n",
              "      <td>-0.532188</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.592403</td>\n",
              "      <td>-0.591524</td>\n",
              "      <td>-0.575158</td>\n",
              "      <td>1.743258</td>\n",
              "      <td>-0.592403</td>\n",
              "      <td>-0.591524</td>\n",
              "      <td>-0.575158</td>\n",
              "      <td>1.743258</td>\n",
              "      <td>-0.592403</td>\n",
              "      <td>b'9'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>-0.706092</td>\n",
              "      <td>-0.706092</td>\n",
              "      <td>1.619903</td>\n",
              "      <td>-0.706092</td>\n",
              "      <td>-0.706092</td>\n",
              "      <td>-0.706092</td>\n",
              "      <td>1.610364</td>\n",
              "      <td>-0.706092</td>\n",
              "      <td>-0.706092</td>\n",
              "      <td>-0.706092</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.702217</td>\n",
              "      <td>-0.956546</td>\n",
              "      <td>0.122643</td>\n",
              "      <td>1.621752</td>\n",
              "      <td>-0.702217</td>\n",
              "      <td>-0.956546</td>\n",
              "      <td>0.122643</td>\n",
              "      <td>1.621752</td>\n",
              "      <td>-0.702217</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>-0.634760</td>\n",
              "      <td>-0.634760</td>\n",
              "      <td>1.584916</td>\n",
              "      <td>-0.634760</td>\n",
              "      <td>-0.634760</td>\n",
              "      <td>-0.634760</td>\n",
              "      <td>1.581811</td>\n",
              "      <td>-0.634760</td>\n",
              "      <td>-0.634760</td>\n",
              "      <td>-0.634760</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.631032</td>\n",
              "      <td>-1.039049</td>\n",
              "      <td>0.085802</td>\n",
              "      <td>1.608606</td>\n",
              "      <td>-0.631032</td>\n",
              "      <td>-1.039049</td>\n",
              "      <td>0.085802</td>\n",
              "      <td>1.608606</td>\n",
              "      <td>-0.631032</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>-0.998277</td>\n",
              "      <td>0.102462</td>\n",
              "      <td>1.606925</td>\n",
              "      <td>-0.692702</td>\n",
              "      <td>-0.998277</td>\n",
              "      <td>0.104508</td>\n",
              "      <td>1.607083</td>\n",
              "      <td>-0.692692</td>\n",
              "      <td>-0.999305</td>\n",
              "      <td>0.105525</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.692653</td>\n",
              "      <td>-0.991113</td>\n",
              "      <td>0.099389</td>\n",
              "      <td>1.563691</td>\n",
              "      <td>-0.692653</td>\n",
              "      <td>-0.991113</td>\n",
              "      <td>0.099389</td>\n",
              "      <td>1.563691</td>\n",
              "      <td>-0.692653</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>-0.941473</td>\n",
              "      <td>0.587214</td>\n",
              "      <td>1.523644</td>\n",
              "      <td>-0.645350</td>\n",
              "      <td>-0.938475</td>\n",
              "      <td>0.585218</td>\n",
              "      <td>1.530411</td>\n",
              "      <td>-0.645379</td>\n",
              "      <td>-0.941473</td>\n",
              "      <td>0.587214</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.645292</td>\n",
              "      <td>-1.046250</td>\n",
              "      <td>0.582230</td>\n",
              "      <td>1.548224</td>\n",
              "      <td>-0.645292</td>\n",
              "      <td>-1.046250</td>\n",
              "      <td>0.582230</td>\n",
              "      <td>1.548224</td>\n",
              "      <td>-0.645292</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>-0.661536</td>\n",
              "      <td>-0.661536</td>\n",
              "      <td>1.510327</td>\n",
              "      <td>-0.661536</td>\n",
              "      <td>-0.661536</td>\n",
              "      <td>-0.661536</td>\n",
              "      <td>1.473648</td>\n",
              "      <td>-0.661536</td>\n",
              "      <td>-0.915802</td>\n",
              "      <td>-0.519394</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.660685</td>\n",
              "      <td>-0.851728</td>\n",
              "      <td>-0.660539</td>\n",
              "      <td>1.510105</td>\n",
              "      <td>-0.660685</td>\n",
              "      <td>-0.851728</td>\n",
              "      <td>-0.660539</td>\n",
              "      <td>1.510105</td>\n",
              "      <td>-0.660685</td>\n",
              "      <td>b'1'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 1461 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-489f64b3-5578-4bda-933f-eb24d3f6b1dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-489f64b3-5578-4bda-933f-eb24d3f6b1dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-489f64b3-5578-4bda-933f-eb24d3f6b1dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "\n",
        "def load_files(main_folder_path):\n",
        "  df_dict = {}\n",
        "  failed_to_load = []\n",
        "  # {folder_name: {test: df, train:df}}\n",
        "  data_folders = os.listdir(main_folder_path)\n",
        "  for f in data_folders:\n",
        "    test_file = glob.glob(f\"{main_folder_path}/{f}/*TEST.arff\")\n",
        "    #print(f\"test_file: {test_file}\")\n",
        "    train_file = glob.glob(f\"{main_folder_path}/{f}/*TRAIN.arff\")\n",
        "    #print(f\"train_file: {train_file}\")\n",
        "    if test_file and train_file:\n",
        "      temp_dict = {\"train\": pd.DataFrame(arff.loadarff(train_file[0])[0]),\n",
        "                  \"test\": pd.DataFrame(arff.loadarff(test_file[0])[0])}\n",
        "      df_dict[f] = temp_dict\n",
        "    else:\n",
        "      print(f)\n",
        "      failed_to_load.append(f)\n",
        "  return df_dict, failed_to_load\n",
        "\n",
        "\n",
        "\n",
        "data_dict, failed_to_load = load_files(f\"{extracted_zip_folder}/Univariate_arff\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu7BOPJ1N-XD",
        "outputId": "3cfb94bf-6419-4cfb-a2c2-075c3447c517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset.csv\n",
            "DataSummaryExpanded_NoMissingVals.xlsx\n",
            "DataSummaryExpanded_v03.xlsx\n",
            "newProblemsUpload.csv\n",
            "Pictures\n",
            "SummaryData.csv\n",
            "TwoClassProblems.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "from itertools import chain\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.lib.stride_tricks import as_strided\n",
        "from scipy.io import arff\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "def load_all_files(\n",
        "    main_folder_path,\n",
        "    exclude_all_dataset,\n",
        "    save_main_folder=None,\n",
        "    min_allowed_nan_vals=0.1,\n",
        "):\n",
        "    data_folders = os.listdir(main_folder_path)\n",
        "    train_datasets = {}\n",
        "    test_datasets = {}\n",
        "    exluded_full_dataset_targets = {}\n",
        "    exluded_full_dataset = {}\n",
        "    failed_to_load_datasets = {}\n",
        "    train_datasets_targets = {}\n",
        "    test_datasets_targets = {}\n",
        "    test_dataset_length = 0\n",
        "    train_dataset_length = 0\n",
        "    print(f\"Total datasets {len(data_folders)}\")\n",
        "    for f in data_folders:\n",
        "        try:\n",
        "            joined_data = pd.DataFrame()\n",
        "            train_and_test_data_joined = pd.DataFrame()\n",
        "            test_file = glob.glob(f\"{main_folder_path}/{f}/*TEST.arff\")\n",
        "            # print(f\"test_file: {test_file}\")\n",
        "            train_file = glob.glob(f\"{main_folder_path}/{f}/*TRAIN.arff\")\n",
        "\n",
        "            if test_file and train_file:\n",
        "                train_df = pd.DataFrame(arff.loadarff(train_file[0])[0])\n",
        "\n",
        "                test_df = pd.DataFrame(arff.loadarff(test_file[0])[0])\n",
        "\n",
        "                # Dropping rows that contain more than 10 % of nan values\n",
        "                train_nan = train_df.isna().sum(axis=1) / train_df.count(axis=1)\n",
        "                train_not_nan = train_nan < min_allowed_nan_vals\n",
        "                train_df = train_df.loc[train_not_nan]\n",
        "\n",
        "                test_nan = test_df.isna().sum(axis=1) / test_df.count(axis=1)\n",
        "                test_not_nan = test_nan < min_allowed_nan_vals\n",
        "                test_df = test_df.loc[test_not_nan]\n",
        "                train_len = len(train_df)\n",
        "                test_len = len(test_df)\n",
        "                if not train_len or not test_len:\n",
        "                    re = (\n",
        "                        \"train and test\"\n",
        "                        if not test_len and not train_len\n",
        "                        else \"train\"\n",
        "                        if not train_len\n",
        "                        else \"test\"\n",
        "                    )\n",
        "                    print(\n",
        "                        f\"Contains too many nan values: {f}, has more than 10 % nan in {re}. Train NaN: {(train_not_nan.mean())}, test NaN: {test_not_nan.mean()}\"\n",
        "                    )\n",
        "                    failed_to_load_datasets[\n",
        "                        f\n",
        "                    ] = f\"Dataset Contains too many nan values in {re} datasets. Train NaN: {(train_not_nan.mean())}, test NaN: {(test_not_nan.mean())}\"\n",
        "                    continue\n",
        "\n",
        "                if f != exclude_all_dataset:\n",
        "\n",
        "                    train_df.fillna(train_df.mean(numeric_only=True), inplace=True)\n",
        "                    test_df.fillna(test_df.mean(numeric_only=True), inplace=True)\n",
        "                    assert not test_df.isna().any().sum(), \"test df contains nulls\"\n",
        "                    assert not train_df.isna().any().sum(), \"train df contains nulls\"\n",
        "                    \n",
        "\n",
        "                    # Processing:\n",
        "                    train_df_columns = train_df.columns\n",
        "                    test_df_columns = test_df.columns\n",
        "                    train_df = StandardScaler().fit_transform(train_df)\n",
        "                    test_df = StandardScaler().fit_transform(test_df)\n",
        "                    train_and_test_data_joined = pd.concat([pd.DataFrame(train_df), pd.DataFrame(test_df)], ignore_index=True)\n",
        "                    train_and_test_data_joined.columns = test_df_columns\n",
        "                    train_df, test_df = train_test_split(train_and_test_data_joined, stratify=train_and_test_data_joined['target'].values, random_state=42, shuffle=True, test_size=0.2)\n",
        "                    train_df.columns = train_df_columns\n",
        "                    test_df.columns = test_df_columns\n",
        "                    if f == 'RightWhaleCalls':\n",
        "                        train_datasets_target = train_df[[\"class\"]]\n",
        "                        test_datasets_target = test_df[[\"class\"]]\n",
        "                    else:\n",
        "                        train_datasets_target = train_df[[\"target\"]]\n",
        "                        test_datasets_target = test_df[[\"target\"]]\n",
        "                    train_datasets_targets[f] = train_datasets_target\n",
        "                    test_datasets_targets[f] = test_datasets_target\n",
        "                    if f == 'RightWhaleCalls':\n",
        "                        train_df.drop(labels=[\"class\"], axis=1, inplace=True)\n",
        "                        test_df.drop(labels=[\"class\"], axis=1, inplace=True)\n",
        "                    else:\n",
        "                        train_df.drop(labels=[\"target\"], axis=1, inplace=True)\n",
        "                        test_df.drop(labels=[\"target\"], axis=1, inplace=True)\n",
        "                    assert (\n",
        "                        not \"target\" in test_df.columns\n",
        "                    ), \"did not remove target column in test df\"\n",
        "                    assert (\n",
        "                        not \"target\" in train_df.columns\n",
        "                    ), \"did not remove target column in train df\"\n",
        "                    # Saving\n",
        "                    train_datasets[f] = pd.DataFrame(train_df)\n",
        "\n",
        "                    test_datasets[f] = pd.DataFrame(test_df)\n",
        "\n",
        "                else:\n",
        "\n",
        "                    joined_data = joined_data.append(train_df, ignore_index=True)\n",
        "                    joined_data = joined_data.append(test_df, ignore_index=True)\n",
        "                    exluded_full_dataset_target = joined_data[[\"target\"]]\n",
        "                    exluded_full_dataset_targets[f] = exluded_full_dataset_target\n",
        "                    joined_data.drop(labels=[\"target\"], axis=1, inplace=True)\n",
        "\n",
        "                    before_na = len(joined_data)\n",
        "                    joined_data = joined_data.loc[\n",
        "                        (\n",
        "                            (joined_data.isna().sum(axis=1) / joined_data.count(axis=1))\n",
        "                            < min_allowed_nan_vals\n",
        "                        )\n",
        "                    ]\n",
        "                    after_na = len(joined_data)\n",
        "                    print(\n",
        "                        f\"Special dataset: {f}, removed nan samples {after_na - before_na}\"\n",
        "                    )\n",
        "                    joined_data.fillna(\n",
        "                        joined_data.mean(numeric_only=True), inplace=True\n",
        "                    )\n",
        "                    assert (\n",
        "                        not joined_data.isna().any().sum()\n",
        "                    ), \"joined_data df contains nulls\"\n",
        "                    joined_data = StandardScaler().fit_transform(joined_data)\n",
        "                    exluded_full_dataset[f] = joined_data\n",
        "                    \n",
        "                if save_main_folder:\n",
        "                    if not os.path.exists(save_main_folder):\n",
        "                        os.mkdir(save_main_folder)\n",
        "                    save_sub_folder = f\"{save_main_folder}/{f}\"\n",
        "                    if not os.path.exists(save_sub_folder):\n",
        "                        os.mkdir(save_sub_folder)\n",
        "                    # saving files:\n",
        "                    if not len(joined_data):\n",
        "                        pd.DataFrame(train_df).to_csv(\n",
        "                        f\"{save_sub_folder}/train.csv\", index=False, encoding=\"utf-8\"\n",
        "                        )\n",
        "                        pd.DataFrame(test_df).to_csv(\n",
        "                            f\"{save_sub_folder}/test.csv\", index=False, encoding=\"utf-8\"\n",
        "                        )\n",
        "                        train_datasets_target.to_csv(\n",
        "                            f\"{save_sub_folder}/train_target.csv\",\n",
        "                            index=False,\n",
        "                            encoding=\"utf-8\",\n",
        "                        )\n",
        "                        test_datasets_target.to_csv(\n",
        "                            f\"{save_sub_folder}/test_target.csv\",\n",
        "                            index=False,\n",
        "                            encoding=\"utf-8\",\n",
        "                        )\n",
        "                    else:\n",
        "                        exluded_full_dataset_target.to_csv(\n",
        "                            f\"{save_sub_folder}/test_target.csv\",\n",
        "                            index=False,\n",
        "                            encoding=\"utf-8\",\n",
        "                        )\n",
        "                        pd.DataFrame(joined_data).to_csv(\n",
        "                            f\"{save_sub_folder}/test.csv\", index=False, encoding=\"utf-8\"\n",
        "                        )\n",
        "            train_dataset_length += len(train_df)\n",
        "            test_dataset_length += len(test_df)\n",
        "            print(f'Dataset {f} | Train {len(train_df)} | Test {len(test_df)}')\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load: {f}\")\n",
        "            failed_to_load_datasets[f] = e\n",
        "            print(f\"Failed saving dataset {f}\")\n",
        "            failed_to_load_datasets[f] = e\n",
        "    print(f'Total training samples {train_dataset_length}')\n",
        "    print(f'Total testing samples {test_dataset_length}')\n",
        "\n",
        "    return (\n",
        "        train_datasets,\n",
        "        test_datasets,\n",
        "        train_datasets_targets,\n",
        "        test_datasets_targets,\n",
        "        exluded_full_dataset,\n",
        "        failed_to_load_datasets,\n",
        "    )\n"
      ],
      "metadata": {
        "id": "KDU_w932cXb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def splitting_data(\n",
        "    df, df_target=None, take_time_stamps=124, overlap=62, zero_padding=True\n",
        "):\n",
        "    def windowed_view_adj(\n",
        "        arr, window=take_time_stamps, overlap=overlap, zero_padding=zero_padding\n",
        "    ):\n",
        "        windows = windowed_view(arr, window, overlap)\n",
        "        if zero_padding:\n",
        "            re = add_zero_padding(arr, window, overlap)\n",
        "            return np.append(windows, re, axis=0)\n",
        "        return windows\n",
        "\n",
        "    def calculate_number_of_created_samples(\n",
        "        arr, window=take_time_stamps, overlap=overlap, zero_padding=zero_padding\n",
        "    ):\n",
        "        window_step = window - overlap\n",
        "        new_shape = ((arr.shape[-1] - overlap) // window_step, window)\n",
        "        return new_shape[0] + 1 if zero_padding else new_shape[0]\n",
        "\n",
        "    vals = df.values\n",
        "    vals_shape = vals.shape\n",
        "    if vals_shape[1] >= take_time_stamps:\n",
        "        if df_target is None:\n",
        "            data = list(map(windowed_view_adj, vals))\n",
        "            return data, None\n",
        "        else:\n",
        "            targ_data = df_target.values\n",
        "            temp_re = [\n",
        "                (\n",
        "                    [\n",
        "                        windowed_view_adj(l),\n",
        "                        np.array(list(d) * calculate_number_of_created_samples(l)),\n",
        "                    ]\n",
        "                )\n",
        "                for l, d in zip(vals, targ_data)\n",
        "            ]\n",
        "            data, data_target = zip(*temp_re)\n",
        "            data = np.array(data)\n",
        "            dat_shape = data.shape\n",
        "            data = data.reshape(dat_shape[0] * dat_shape[1], dat_shape[-1])\n",
        "            data_target = list(chain(*data_target))\n",
        "            assert data.shape[0] == len(\n",
        "                data_target\n",
        "            ), \"Target and data rows are different size!\"\n",
        "            return data, data_target\n",
        "\n",
        "    else:\n",
        "        print(\"Not enough samples\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def windowed_view(arr, window, overlap):\n",
        "    arr = np.asarray(arr)\n",
        "    window_step = window - overlap\n",
        "    new_shape = arr.shape[:-1] + ((arr.shape[-1] - overlap) // window_step, window)\n",
        "    new_strides = arr.strides[:-1] + (window_step * arr.strides[-1],) + arr.strides[-1:]\n",
        "    return as_strided(arr, shape=new_shape, strides=new_strides)\n",
        "\n",
        "\n",
        "def add_zero_padding(arr, window, overlap):\n",
        "    # need_zeros = len(arr)\n",
        "    array_len = len(arr)\n",
        "    window_step = window - overlap\n",
        "    number_of_els = (arr.shape[-1] - overlap) // window_step\n",
        "    take_ind = number_of_els * window_step\n",
        "    number_of_left_elements = array_len - take_ind\n",
        "    padded_arr = np.array(\n",
        "        list(arr[take_ind:]) + (window - number_of_left_elements) * [0]\n",
        "    ).reshape(1, window)\n",
        "    assert padded_arr.shape == (\n",
        "        1,\n",
        "        window,\n",
        "    ), f\"Wrong dimensions after zero padding, expected (1, {window}), got {padded_arr.shape}\"\n",
        "    return padded_arr\n",
        "\n",
        "\n",
        "def load_preprocessed_datasets_and_processe(\n",
        "    main_data_folder,\n",
        "    exclude_dataset_for_testing,\n",
        "    save_result_folder=None,\n",
        "    windows_size=128,\n",
        "    overlap=64,\n",
        "    zero_padding=False,\n",
        "):\n",
        "    train_data_dict = {}\n",
        "    test_data_dict = {}\n",
        "    train_target_dict = {}\n",
        "    test_target_dict = {}\n",
        "    data_folders = os.listdir(main_data_folder)\n",
        "    exceptions = {}\n",
        "    print(f\"Total datasets {len(data_folders)}\")\n",
        "    for f in data_folders:\n",
        "        try:\n",
        "            test_df = pd.read_csv(f\"{main_data_folder}/{f}/test.csv\")\n",
        "            target_test_df = pd.read_csv(f\"{main_data_folder}/{f}/test_target.csv\")\n",
        "            test_shape = test_df.shape\n",
        "            if test_shape[1] < windows_size:\n",
        "                exceptions[\n",
        "                    f\n",
        "                ] = f\"Not enough samples in row, found {test_shape[1]}, expected (window size) {windows_size}\"\n",
        "                continue\n",
        "            if f == exclude_dataset_for_testing:\n",
        "                splitted_train, splitted_train_target = pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "            else:\n",
        "                train_df = pd.read_csv(f\"{main_data_folder}/{f}/train.csv\")\n",
        "                test_df = pd.read_csv(f\"{main_data_folder}/{f}/test.csv\")\n",
        "                target_train_df = pd.read_csv(\n",
        "                    f\"{main_data_folder}/{f}/train_target.csv\"\n",
        "                )\n",
        "\n",
        "                splitted_train, splitted_train_target = splitting_data(\n",
        "                    train_df,\n",
        "                    target_train_df,\n",
        "                    take_time_stamps=windows_size,\n",
        "                    overlap=overlap,\n",
        "                    zero_padding=zero_padding,\n",
        "                )\n",
        "            splitted_test, splitted_test_target = splitting_data(\n",
        "                test_df,\n",
        "                target_test_df,\n",
        "                take_time_stamps=windows_size,\n",
        "                overlap=overlap,\n",
        "                zero_padding=zero_padding,\n",
        "            )\n",
        "            if save_result_folder:\n",
        "                if not os.path.exists(save_result_folder):\n",
        "                    os.mkdir(save_result_folder)\n",
        "                additional_folder = f\"{save_result_folder}/w_{windows_size}_o_{overlap}_p_{int(zero_padding)}\"\n",
        "                if not os.path.exists(additional_folder):\n",
        "                    os.mkdir(additional_folder)\n",
        "                dataset_folder = f\"{additional_folder}/{f}\"\n",
        "                if not os.path.exists(dataset_folder):\n",
        "                    os.mkdir(dataset_folder)\n",
        "\n",
        "                # splitted_train = None\n",
        "                pd.DataFrame(splitted_test).to_csv(\n",
        "                    f\"{dataset_folder}/test.csv\", index=False, encoding=\"utf-8\"\n",
        "                )\n",
        "                pd.DataFrame(splitted_test_target).to_csv(\n",
        "                    f\"{dataset_folder}/test_target.csv\", index=False, encoding=\"utf-8\"\n",
        "                )\n",
        "                if len(splitted_train):\n",
        "                    pd.DataFrame(splitted_train).to_csv(\n",
        "                        f\"{dataset_folder}/train.csv\", index=False, encoding=\"utf-8\"\n",
        "                    )\n",
        "                    pd.DataFrame(splitted_train_target).to_csv(\n",
        "                        f\"{dataset_folder}/train_target.csv\",\n",
        "                        index=False,\n",
        "                        encoding=\"utf-8\",\n",
        "                    )\n",
        "            else:\n",
        "                test_target_dict[f] = splitted_test_target\n",
        "                test_data_dict[f] = splitted_test\n",
        "                if len(splitted_train):\n",
        "                    train_target_dict[f] = splitted_train_target\n",
        "                    train_data_dict[f] = splitted_train\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with {f}: {e}\")\n",
        "            exceptions[f] = e\n",
        "    return (\n",
        "        train_data_dict,\n",
        "        test_data_dict,\n",
        "        train_target_dict,\n",
        "        test_target_dict,\n",
        "        exceptions,\n",
        "    )"
      ],
      "metadata": {
        "id": "vrbWQo0F05f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_folder_path = \"extracted_univariate_time_series/Univariate_arff\"\n",
        "\n",
        "exclude_dataset_for_testing = \"InsectSound\"\n",
        "\n",
        "(\n",
        "  train_datasets,\n",
        "  test_datasets,\n",
        "  train_datasets_target,\n",
        "  test_datasets_target,\n",
        "  exluded_full_dataset,\n",
        "  failed_to_load_datasets,\n",
        ") = load_all_files(main_folder_path, exclude_dataset_for_testing, \"processed_datasets\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "470pqFpBclH-",
        "outputId": "8aa4e49d-846f-4580-f1dd-e0b2864435c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total datasets 135\n",
            "Dataset ACSF1 | Train 160 | Test 40\n",
            "Dataset Adiac | Train 624 | Test 157\n",
            "Contains too many nan values: AllGestureWiimoteX, has more than 10 % nan in train and test. Train NaN: 0.0, test NaN: 0.0\n",
            "Contains too many nan values: AllGestureWiimoteY, has more than 10 % nan in train and test. Train NaN: 0.0, test NaN: 0.0\n",
            "Contains too many nan values: AllGestureWiimoteZ, has more than 10 % nan in train and test. Train NaN: 0.0, test NaN: 0.0\n",
            "Dataset ArrowHead | Train 168 | Test 43\n",
            "Dataset Beef | Train 48 | Test 12\n",
            "Dataset BeetleFly | Train 32 | Test 8\n",
            "Dataset BirdChicken | Train 32 | Test 8\n",
            "Dataset BME | Train 144 | Test 36\n",
            "Dataset Car | Train 96 | Test 24\n",
            "Dataset CBF | Train 744 | Test 186\n",
            "Dataset Chinatown | Train 290 | Test 73\n",
            "Dataset ChlorineConcentration | Train 3445 | Test 862\n",
            "Dataset CinCECGTorso | Train 1136 | Test 284\n",
            "Dataset Coffee | Train 44 | Test 12\n",
            "Dataset Computers | Train 400 | Test 100\n",
            "Dataset CricketX | Train 624 | Test 156\n",
            "Dataset CricketY | Train 624 | Test 156\n",
            "Dataset CricketZ | Train 624 | Test 156\n",
            "Dataset Crop | Train 19200 | Test 4800\n",
            "Dataset dataset.csv | Train 19200 | Test 4800\n",
            "Dataset DataSummaryExpanded_NoMissingVals.xlsx | Train 19200 | Test 4800\n",
            "Dataset DataSummaryExpanded_v03.xlsx | Train 19200 | Test 4800\n",
            "Failed to load: DiatomSizeReduction\n",
            "Failed saving dataset DiatomSizeReduction\n",
            "Dataset DistalPhalanxOutlineAgeGroup | Train 431 | Test 108\n",
            "Dataset DistalPhalanxOutlineCorrect | Train 700 | Test 176\n",
            "Dataset DistalPhalanxTW | Train 431 | Test 108\n",
            "Dataset DodgerLoopDay | Train 122 | Test 31\n",
            "Dataset DodgerLoopGame | Train 122 | Test 31\n",
            "Dataset DodgerLoopWeekend | Train 122 | Test 31\n",
            "Dataset Earthquakes | Train 368 | Test 93\n",
            "Dataset ECG200 | Train 160 | Test 40\n",
            "Dataset ECG5000 | Train 4000 | Test 1000\n",
            "Dataset ECGFiveDays | Train 707 | Test 177\n",
            "Dataset ElectricDevices | Train 13309 | Test 3328\n",
            "Dataset EOGHorizontalSignal | Train 579 | Test 145\n",
            "Dataset EOGVerticalSignal | Train 579 | Test 145\n",
            "Dataset EthanolLevel | Train 803 | Test 201\n",
            "Dataset FaceAll | Train 1800 | Test 450\n",
            "Dataset FaceFour | Train 89 | Test 23\n",
            "Dataset FacesUCR | Train 1800 | Test 450\n",
            "Failed to load: FiftyWords\n",
            "Failed saving dataset FiftyWords\n",
            "Dataset Fish | Train 280 | Test 70\n",
            "Dataset FordA | Train 3936 | Test 985\n",
            "Dataset FordB | Train 3556 | Test 890\n",
            "Dataset FreezerRegularTrain | Train 2400 | Test 600\n",
            "Dataset FreezerSmallTrain | Train 2302 | Test 576\n",
            "Failed to load: Fungi\n",
            "Failed saving dataset Fungi\n",
            "Dataset GestureMidAirD1 | Train 9 | Test 3\n",
            "Dataset GestureMidAirD2 | Train 9 | Test 3\n",
            "Dataset GestureMidAirD3 | Train 9 | Test 3\n",
            "Contains too many nan values: GesturePebbleZ1, has more than 10 % nan in test. Train NaN: 0.05303030303030303, test NaN: 0.0\n",
            "Contains too many nan values: GesturePebbleZ2, has more than 10 % nan in test. Train NaN: 0.04794520547945205, test NaN: 0.0\n",
            "Dataset GunPoint | Train 160 | Test 40\n",
            "Dataset GunPointAgeSpan | Train 360 | Test 91\n",
            "Dataset GunPointMaleVersusFemale | Train 360 | Test 91\n",
            "Dataset GunPointOldVersusYoung | Train 360 | Test 91\n",
            "Dataset Ham | Train 171 | Test 43\n",
            "Dataset HandOutlines | Train 1096 | Test 274\n",
            "Dataset Haptics | Train 370 | Test 93\n",
            "Dataset Herring | Train 102 | Test 26\n",
            "Dataset HouseTwenty | Train 127 | Test 32\n",
            "Dataset InlineSkate | Train 520 | Test 130\n",
            "Dataset InsectEPGRegularTrain | Train 248 | Test 63\n",
            "Dataset InsectEPGSmallTrain | Train 212 | Test 54\n",
            "Dataset InsectWingbeatSound | Train 1760 | Test 440\n",
            "Dataset ItalyPowerDemand | Train 876 | Test 220\n",
            "Dataset LargeKitchenAppliances | Train 600 | Test 150\n",
            "Dataset Lightning2 | Train 96 | Test 25\n",
            "Dataset Lightning7 | Train 114 | Test 29\n",
            "Dataset Mallat | Train 1920 | Test 480\n",
            "Dataset Meat | Train 96 | Test 24\n",
            "Dataset MedicalImages | Train 912 | Test 229\n",
            "Dataset MelbournePedestrian | Train 2897 | Test 725\n",
            "Dataset MiddlePhalanxOutlineAgeGroup | Train 443 | Test 111\n",
            "Dataset MiddlePhalanxOutlineCorrect | Train 712 | Test 179\n",
            "Dataset MiddlePhalanxTW | Train 442 | Test 111\n",
            "Dataset MixedShapesRegularTrain | Train 2340 | Test 585\n",
            "Dataset MixedShapesSmallTrain | Train 2020 | Test 505\n",
            "Dataset MoteStrain | Train 1017 | Test 255\n",
            "Dataset newProblemsUpload.csv | Train 1017 | Test 255\n",
            "Dataset NonInvasiveFetalECGThorax1 | Train 3012 | Test 753\n",
            "Dataset NonInvasiveFetalECGThorax2 | Train 3012 | Test 753\n",
            "Dataset OliveOil | Train 48 | Test 12\n",
            "Dataset OSULeaf | Train 353 | Test 89\n",
            "Dataset PhalangesOutlinesCorrect | Train 2126 | Test 532\n",
            "Failed to load: Phoneme\n",
            "Failed saving dataset Phoneme\n",
            "Contains too many nan values: PickupGestureWiimoteZ, has more than 10 % nan in test. Train NaN: 0.04, test NaN: 0.0\n",
            "Dataset Pictures | Train 2 | Test 0\n",
            "Dataset PigAirwayPressure | Train 249 | Test 63\n",
            "Dataset PigArtPressure | Train 249 | Test 63\n",
            "Dataset PigCVP | Train 249 | Test 63\n",
            "Contains too many nan values: PLAID, has more than 10 % nan in test. Train NaN: 0.00186219739292365, test NaN: 0.0\n",
            "Dataset Plane | Train 168 | Test 42\n",
            "Dataset PowerCons | Train 288 | Test 72\n",
            "Dataset ProximalPhalanxOutlineAgeGroup | Train 484 | Test 121\n",
            "Dataset ProximalPhalanxOutlineCorrect | Train 712 | Test 179\n",
            "Dataset ProximalPhalanxTW | Train 484 | Test 121\n",
            "Dataset RefrigerationDevices | Train 600 | Test 150\n",
            "Dataset Rock | Train 56 | Test 14\n",
            "Dataset ScreenType | Train 600 | Test 150\n",
            "Dataset SemgHandGenderCh2 | Train 720 | Test 180\n",
            "Dataset SemgHandMovementCh2 | Train 720 | Test 180\n",
            "Dataset SemgHandSubjectCh2 | Train 720 | Test 180\n",
            "Failed to load: ShakeGestureWiimoteZ\n",
            "Failed saving dataset ShakeGestureWiimoteZ\n",
            "Dataset ShapeletSim | Train 160 | Test 40\n",
            "Dataset ShapesAll | Train 960 | Test 240\n",
            "Dataset SmallKitchenAppliances | Train 600 | Test 150\n",
            "Dataset SmoothSubspace | Train 240 | Test 60\n",
            "Dataset SonyAIBORobotSurface1 | Train 496 | Test 125\n",
            "Dataset SonyAIBORobotSurface2 | Train 784 | Test 196\n",
            "Dataset StarLightCurves | Train 7388 | Test 1848\n",
            "Dataset Strawberry | Train 786 | Test 197\n",
            "Dataset SummaryData.csv | Train 786 | Test 197\n",
            "Dataset SwedishLeaf | Train 900 | Test 225\n",
            "Dataset Symbols | Train 816 | Test 204\n",
            "Dataset SyntheticControl | Train 480 | Test 120\n",
            "Dataset ToeSegmentation1 | Train 214 | Test 54\n",
            "Dataset ToeSegmentation2 | Train 132 | Test 34\n",
            "Dataset Trace | Train 160 | Test 40\n",
            "Dataset TwoClassProblems.csv | Train 160 | Test 40\n",
            "Dataset TwoLeadECG | Train 929 | Test 233\n",
            "Dataset TwoPatterns | Train 4000 | Test 1000\n",
            "Dataset UMD | Train 144 | Test 36\n",
            "Dataset UWaveGestureLibraryAll | Train 3582 | Test 896\n",
            "Dataset UWaveGestureLibraryX | Train 3582 | Test 896\n",
            "Dataset UWaveGestureLibraryY | Train 3582 | Test 896\n",
            "Dataset UWaveGestureLibraryZ | Train 3582 | Test 896\n",
            "Dataset Wafer | Train 5731 | Test 1433\n",
            "Dataset Wine | Train 88 | Test 23\n",
            "Dataset WordSynonyms | Train 724 | Test 181\n",
            "Dataset Worms | Train 206 | Test 52\n",
            "Dataset WormsTwoClass | Train 206 | Test 52\n",
            "Dataset Yoga | Train 2640 | Test 660\n",
            "Total training samples 204916\n",
            "Total testing samples 51272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exclude_dataset_for_testing = \"InsectSound\"\n",
        "(\n",
        "    train_data_dict,\n",
        "    test_data_dict,\n",
        "    train_target_dict,\n",
        "    test_target_dict,\n",
        "    exceptions,\n",
        ") = load_preprocessed_datasets_and_processe(\n",
        "    \"processed_datasets\", exclude_dataset_for_testing,\n",
        "    save_result_folder='fully_processed_data', windows_size=128, overlap=64\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re_BPmZG1GJf",
        "outputId": "cb09c1ce-5858-4b4f-a718-52f0458b8dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total datasets 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exceptions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E1x9U6x3j2J",
        "outputId": "4ddc1ff8-4aea-43fe-8599-fafcc630816c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Chinatown': 'Not enough samples in row, found 24, expected (window size) 128',\n",
              " 'Crop': 'Not enough samples in row, found 46, expected (window size) 128',\n",
              " 'DistalPhalanxOutlineAgeGroup': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'DistalPhalanxOutlineCorrect': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'DistalPhalanxTW': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'ECG200': 'Not enough samples in row, found 96, expected (window size) 128',\n",
              " 'ElectricDevices': 'Not enough samples in row, found 96, expected (window size) 128',\n",
              " 'ItalyPowerDemand': 'Not enough samples in row, found 24, expected (window size) 128',\n",
              " 'MedicalImages': 'Not enough samples in row, found 99, expected (window size) 128',\n",
              " 'MelbournePedestrian': 'Not enough samples in row, found 24, expected (window size) 128',\n",
              " 'MiddlePhalanxOutlineAgeGroup': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'MiddlePhalanxOutlineCorrect': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'MiddlePhalanxTW': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'MoteStrain': 'Not enough samples in row, found 84, expected (window size) 128',\n",
              " 'PhalangesOutlinesCorrect': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'ProximalPhalanxOutlineAgeGroup': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'ProximalPhalanxOutlineCorrect': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'ProximalPhalanxTW': 'Not enough samples in row, found 80, expected (window size) 128',\n",
              " 'SmoothSubspace': 'Not enough samples in row, found 15, expected (window size) 128',\n",
              " 'SonyAIBORobotSurface1': 'Not enough samples in row, found 70, expected (window size) 128',\n",
              " 'SonyAIBORobotSurface2': 'Not enough samples in row, found 65, expected (window size) 128',\n",
              " 'SyntheticControl': 'Not enough samples in row, found 60, expected (window size) 128',\n",
              " 'TwoLeadECG': 'Not enough samples in row, found 82, expected (window size) 128'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "failed_to_load_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JNFIWlBdMO8",
        "outputId": "afb8053a-8c6c-4ebb-cbc8-f30db6f0fb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AllGestureWiimoteX': 'Dataset Contains too many nan values in train and test datasets. Train NaN: 0.0, test NaN: 0.0',\n",
              " 'AllGestureWiimoteY': 'Dataset Contains too many nan values in train and test datasets. Train NaN: 0.0, test NaN: 0.0',\n",
              " 'AllGestureWiimoteZ': 'Dataset Contains too many nan values in train and test datasets. Train NaN: 0.0, test NaN: 0.0',\n",
              " 'DiatomSizeReduction': ValueError('The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.'),\n",
              " 'FiftyWords': ValueError('The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.'),\n",
              " 'Fungi': ValueError('The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.'),\n",
              " 'GesturePebbleZ1': 'Dataset Contains too many nan values in test datasets. Train NaN: 0.05303030303030303, test NaN: 0.0',\n",
              " 'GesturePebbleZ2': 'Dataset Contains too many nan values in test datasets. Train NaN: 0.04794520547945205, test NaN: 0.0',\n",
              " 'Phoneme': ValueError('The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.'),\n",
              " 'PickupGestureWiimoteZ': 'Dataset Contains too many nan values in test datasets. Train NaN: 0.04, test NaN: 0.0',\n",
              " 'PLAID': 'Dataset Contains too many nan values in test datasets. Train NaN: 0.00186219739292365, test NaN: 0.0',\n",
              " 'ShakeGestureWiimoteZ': AssertionError('test df contains nulls')}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVBsDRXUOyZV",
        "outputId": "502d131e-c386-4e02-ef95-a6fe44a9359d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY', 'AllGestureWiimoteZ', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken', 'BME', 'Car', 'CBF', 'Chinatown', 'ChlorineConcentration', 'CinCECGTorso', 'Coffee', 'Computers', 'CricketX', 'CricketY', 'CricketZ', 'Crop', 'DiatomSizeReduction', 'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame', 'DodgerLoopWeekend', 'Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays', 'ElectricDevices', 'EOGHorizontalSignal', 'EOGVerticalSignal', 'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords', 'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain', 'Fungi', 'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3', 'GesturePebbleZ1', 'GesturePebbleZ2', 'GunPoint', 'GunPointAgeSpan', 'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham', 'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate', 'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound', 'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2', 'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian', 'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect', 'MiddlePhalanxTW', 'MixedShapesRegularTrain', 'MixedShapesSmallTrain', 'MoteStrain', 'NonInvasiveFetalECGThorax1', 'NonInvasiveFetalECGThorax2', 'OliveOil', 'OSULeaf', 'PhalangesOutlinesCorrect', 'Phoneme', 'PickupGestureWiimoteZ', 'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'PLAID', 'Plane', 'PowerCons', 'ProximalPhalanxOutlineAgeGroup', 'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW', 'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2', 'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ', 'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SmoothSubspace', 'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarLightCurves', 'Strawberry', 'SwedishLeaf', 'Symbols', 'SyntheticControl', 'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG', 'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX', 'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine', 'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random as rnd\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# 5 % datasets for testing (7 datasets), and taking 5 % of dataset test sets for additional testing\n",
        "def train_test_data(df_dict, no_full_test_sets=7, no_partial_test_sets=7):\n",
        "  total_set_dict = dict(zip(range(0, len(df_dict)), list(df_dict.keys())))\n",
        "  # taking 7 datasets for testing\n",
        "  indexes_list = list(total_set_dict.keys())\n",
        "  full_test_sets_indexes = rnd.sample(indexes_list, no_full_test_sets)\n",
        "  indexes_list = [el for el in indexes_list if not el in full_test_sets_indexes]\n",
        "  partial_test_sets_indexes = rnd.sample(indexes_list, no_partial_test_sets)\n",
        "  indexes_list = [el for el in indexes_list if not el in partial_test_sets_indexes]\n",
        "  full_test_sets = {el: df_dict[el] for el in df_dict.keys() if el in np.array(list(total_set_dict.values()))[list(full_test_sets_indexes)]}\n",
        "  partial_test_sets = {el: df_dict[el]['test'] for el in df_dict.keys() if el in np.array(list(total_set_dict.values()))[list(partial_test_sets_indexes)]}\n",
        "  full_train_sets = {el: df_dict[el] for el in df_dict.keys() if el in np.array(list(total_set_dict.values()))[list(indexes_list)]}\n",
        "  partial_train_sets = {el: df_dict[el]['train'] for el in df_dict.keys() if el in np.array(list(total_set_dict.values()))[list(partial_test_sets_indexes)]}\n",
        "  return full_test_sets, partial_test_sets, full_train_sets, partial_train_sets\n",
        "\n",
        "full_test_sets, partial_test_sets, full_train_sets, partial_train_sets = train_test_data(data_dict)\n"
      ],
      "metadata": {
        "id": "c1YyitKUO4ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_test_sets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uphkpVvdk7tD",
        "outputId": "130cf24f-fabc-42eb-c240-54aec63a10ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ACSF1': {'train':         att1      att2      att3      att4      att5      att6      att7  \\\n",
              "  0  -0.584754 -0.584754  1.730991 -0.584754 -0.584754 -0.584754  1.729917   \n",
              "  1  -0.591434 -0.511104  1.726820 -0.580422 -0.591434 -0.511104  1.727921   \n",
              "  2  -0.577945 -0.577945  1.730793 -0.577945 -0.578946 -0.564882  1.731094   \n",
              "  3  -0.588925 -0.538088  1.735718 -0.588716 -0.589962 -0.523551  1.735619   \n",
              "  4  -0.596633 -0.532188  1.718067 -0.592117 -0.596633 -0.532188  1.715241   \n",
              "  ..       ...       ...       ...       ...       ...       ...       ...   \n",
              "  95 -0.706092 -0.706092  1.619903 -0.706092 -0.706092 -0.706092  1.610364   \n",
              "  96 -0.634760 -0.634760  1.584916 -0.634760 -0.634760 -0.634760  1.581811   \n",
              "  97 -0.998277  0.102462  1.606925 -0.692702 -0.998277  0.104508  1.607083   \n",
              "  98 -0.941473  0.587214  1.523644 -0.645350 -0.938475  0.585218  1.530411   \n",
              "  99 -0.661536 -0.661536  1.510327 -0.661536 -0.661536 -0.661536  1.473648   \n",
              "  \n",
              "          att8      att9     att10  ...   att1452   att1453   att1454   att1455  \\\n",
              "  0  -0.584754 -0.584754 -0.584754  ... -0.584734 -0.583729 -0.578603  1.732726   \n",
              "  1  -0.580422 -0.591434 -0.511104  ... -0.580731 -0.580731 -0.580731  1.727396   \n",
              "  2  -0.577829 -0.580956 -0.548788  ... -0.577751 -0.580956 -0.549798  1.734727   \n",
              "  3  -0.588646 -0.588925 -0.524598  ... -0.588876 -0.586852 -0.576483  1.743664   \n",
              "  4  -0.592117 -0.595605 -0.532188  ... -0.592403 -0.591524 -0.575158  1.743258   \n",
              "  ..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
              "  95 -0.706092 -0.706092 -0.706092  ... -0.702217 -0.956546  0.122643  1.621752   \n",
              "  96 -0.634760 -0.634760 -0.634760  ... -0.631032 -1.039049  0.085802  1.608606   \n",
              "  97 -0.692692 -0.999305  0.105525  ... -0.692653 -0.991113  0.099389  1.563691   \n",
              "  98 -0.645379 -0.941473  0.587214  ... -0.645292 -1.046250  0.582230  1.548224   \n",
              "  99 -0.661536 -0.915802 -0.519394  ... -0.660685 -0.851728 -0.660539  1.510105   \n",
              "  \n",
              "       att1456   att1457   att1458   att1459   att1460  target  \n",
              "  0  -0.584734 -0.583729 -0.578603  1.732726 -0.584734    b'9'  \n",
              "  1  -0.580731 -0.580731 -0.580731  1.727396 -0.580731    b'9'  \n",
              "  2  -0.577751 -0.580956 -0.549798  1.734727 -0.577751    b'9'  \n",
              "  3  -0.588876 -0.586852 -0.576483  1.743664 -0.588876    b'9'  \n",
              "  4  -0.592403 -0.591524 -0.575158  1.743258 -0.592403    b'9'  \n",
              "  ..       ...       ...       ...       ...       ...     ...  \n",
              "  95 -0.702217 -0.956546  0.122643  1.621752 -0.702217    b'1'  \n",
              "  96 -0.631032 -1.039049  0.085802  1.608606 -0.631032    b'1'  \n",
              "  97 -0.692653 -0.991113  0.099389  1.563691 -0.692653    b'1'  \n",
              "  98 -0.645292 -1.046250  0.582230  1.548224 -0.645292    b'1'  \n",
              "  99 -0.660685 -0.851728 -0.660539  1.510105 -0.660685    b'1'  \n",
              "  \n",
              "  [100 rows x 1461 columns],\n",
              "  'test':         att1      att2      att3      att4      att5      att6      att7  \\\n",
              "  0  -0.577967 -0.577967  1.738162 -0.577967 -0.577967 -0.577967  1.736333   \n",
              "  1  -0.588575 -0.588575  1.723134 -0.588575 -0.588575 -0.588575  1.724207   \n",
              "  2  -0.582897 -0.573761  1.753402 -0.582838 -0.582897 -0.582897  1.754501   \n",
              "  3  -0.590951 -0.537474  1.743933 -0.590733 -0.591978 -0.527198  1.715386   \n",
              "  4  -0.576821 -0.563665  1.730566 -0.577710 -0.576821 -0.563665  1.729412   \n",
              "  ..       ...       ...       ...       ...       ...       ...       ...   \n",
              "  95 -0.865824  0.116534  1.665577 -0.664466 -0.668138 -0.668138  1.667320   \n",
              "  96 -0.631937 -0.631937  1.612754 -0.631937 -0.631937 -0.631937  1.602539   \n",
              "  97 -0.997077  0.108756  1.585963 -0.695920 -0.996043  0.106678  1.585752   \n",
              "  98 -0.891590 -0.752940  1.424231 -0.752324 -0.891590 -0.751933  1.421933   \n",
              "  99 -0.845868 -0.650711  1.561223 -0.650859 -0.845868 -0.650711  1.561076   \n",
              "  \n",
              "          att8      att9     att10  ...   att1452   att1453   att1454   att1455  \\\n",
              "  0  -0.577967 -0.577967 -0.577967  ... -0.577967 -0.577967 -0.577967  1.716743   \n",
              "  1  -0.588575 -0.588575 -0.588575  ... -0.588430 -0.591796 -0.554190  1.742432   \n",
              "  2  -0.582897 -0.585939 -0.555469  ... -0.582681 -0.585939 -0.553437  1.724040   \n",
              "  3  -0.590684 -0.591978 -0.527198  ... -0.590891 -0.588895 -0.575526  1.728123   \n",
              "  4  -0.577710 -0.576821 -0.563665  ... -0.577828 -0.577828 -0.577828  1.739030   \n",
              "  ..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
              "  95 -0.668138 -0.668138 -0.668138  ... -0.664985 -0.842507  0.008064  1.672843   \n",
              "  96 -0.631937 -0.631937 -0.631937  ... -0.628213 -1.017398  0.088009  1.573765   \n",
              "  97 -0.695931 -0.994998  0.107722  ... -0.695931 -0.996043  0.106678  1.589317   \n",
              "  98 -0.752324 -0.892596 -0.747885  ... -0.747132 -1.069707  0.481769  1.431407   \n",
              "  99 -0.650859 -0.846880 -0.650711  ... -0.646646 -0.989189  0.434901  1.553132   \n",
              "  \n",
              "       att1456   att1457   att1458   att1459   att1460  target  \n",
              "  0  -0.577967 -0.577967 -0.577967  1.716743 -0.577967    b'9'  \n",
              "  1  -0.588430 -0.591796 -0.554190  1.742432 -0.588430    b'9'  \n",
              "  2  -0.582681 -0.585939 -0.553437  1.724040 -0.582681    b'9'  \n",
              "  3  -0.590891 -0.588895 -0.575526  1.728123 -0.590891    b'9'  \n",
              "  4  -0.577828 -0.577828 -0.577828  1.739030 -0.577828    b'9'  \n",
              "  ..       ...       ...       ...       ...       ...     ...  \n",
              "  95 -0.664985 -0.842507  0.008064  1.672843 -0.664985    b'1'  \n",
              "  96 -0.628213 -1.017398  0.088009  1.573765 -0.628213    b'1'  \n",
              "  97 -0.695931 -0.996043  0.106678  1.589317 -0.695931    b'1'  \n",
              "  98 -0.747132 -1.069707  0.481769  1.431407 -0.747132    b'1'  \n",
              "  99 -0.646646 -0.989189  0.434901  1.553132 -0.646646    b'1'  \n",
              "  \n",
              "  [100 rows x 1461 columns]},\n",
              " 'AllGestureWiimoteY': {'train':       att1   att2   att3   att4   att5   att6   att7   att8   att9  att10  \\\n",
              "  0    0.074  0.037  0.037  0.000  0.074  0.074  0.148  0.222  0.222  0.222   \n",
              "  1    0.148  0.148  0.222  0.111  0.037  0.000  0.074  0.000  0.000  0.074   \n",
              "  2    0.074  0.111  0.111  0.148  0.074  0.037  0.074  0.111  0.222  0.222   \n",
              "  3   -0.037  0.000  0.000  0.000  0.000 -0.037 -0.037  0.037  0.037  0.000   \n",
              "  4    0.037  0.000  0.000  0.074 -0.037  0.000  0.111  0.074  0.074  0.111   \n",
              "  ..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "  295  0.037 -0.037  0.074  0.111  0.259  0.259  0.333  0.407  0.444  0.481   \n",
              "  296 -0.074 -0.037 -0.037 -0.037 -0.037 -0.037  0.000 -0.037 -0.037 -0.037   \n",
              "  297  0.000 -0.037 -0.037 -0.037 -0.037 -0.037  0.000  0.000 -0.037  0.000   \n",
              "  298  0.037 -0.111 -0.074 -0.037 -0.074 -0.074 -0.074 -0.074 -0.074 -0.074   \n",
              "  299  0.037  0.074  0.111  0.148  0.185  0.185  0.148  0.185  0.185  0.185   \n",
              "  \n",
              "       ...  att492  att493  att494  att495  att496  att497  att498  att499  \\\n",
              "  0    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  1    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  2    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  3    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  4    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  ..   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "  295  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  296  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  297  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  298  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  299  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  \n",
              "       att500  target  \n",
              "  0       NaN    b'1'  \n",
              "  1       NaN    b'1'  \n",
              "  2       NaN    b'1'  \n",
              "  3       NaN    b'1'  \n",
              "  4       NaN    b'1'  \n",
              "  ..      ...     ...  \n",
              "  295     NaN   b'10'  \n",
              "  296     NaN   b'10'  \n",
              "  297     NaN   b'10'  \n",
              "  298     NaN   b'10'  \n",
              "  299     NaN   b'10'  \n",
              "  \n",
              "  [300 rows x 501 columns],\n",
              "  'test':       att1   att2   att3   att4   att5   att6   att7   att8   att9  att10  \\\n",
              "  0    0.037  0.037  0.037  0.037  0.111  0.074  0.074  0.074  0.074  0.074   \n",
              "  1    0.000  0.000  0.037  0.037  0.037  0.037  0.037  0.037  0.037  0.037   \n",
              "  2    0.037  0.037  0.037  0.037  0.037  0.037  0.037  0.037  0.037  0.074   \n",
              "  3   -0.037  0.111  0.037  0.037  0.037  0.037  0.037  0.037  0.037  0.037   \n",
              "  4    0.000  0.037  0.074  0.037  0.037  0.000  0.000  0.000  0.074  0.074   \n",
              "  ..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "  695 -0.074 -0.111 -0.111 -0.111 -0.074 -0.037  0.037  0.037  0.000  0.000   \n",
              "  696  1.296  1.704  2.148  2.444  2.444  2.370  2.148  1.889  1.556  1.185   \n",
              "  697 -0.148 -0.148 -0.111 -0.111 -0.148 -0.148 -0.148 -0.148 -0.148 -0.148   \n",
              "  698 -0.148 -0.148 -0.111 -0.148 -0.111 -0.111 -0.111 -0.148 -0.111 -0.111   \n",
              "  699  1.370  1.370  1.593  1.704  1.630  1.556  1.370  1.370  1.185  0.963   \n",
              "  \n",
              "       ...  att492  att493  att494  att495  att496  att497  att498  att499  \\\n",
              "  0    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  1    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  2    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  3    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  4    ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  ..   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "  695  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  696  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  697  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  698  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  699  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "  \n",
              "       att500  target  \n",
              "  0       NaN    b'1'  \n",
              "  1       NaN    b'1'  \n",
              "  2       NaN    b'1'  \n",
              "  3       NaN    b'1'  \n",
              "  4       NaN    b'1'  \n",
              "  ..      ...     ...  \n",
              "  695     NaN   b'10'  \n",
              "  696     NaN   b'10'  \n",
              "  697     NaN   b'10'  \n",
              "  698     NaN   b'10'  \n",
              "  699     NaN   b'10'  \n",
              "  \n",
              "  [700 rows x 501 columns]},\n",
              " 'BeetleFly': {'train':         att1      att2      att3      att4      att5      att6      att7  \\\n",
              "  0   1.246789  1.174937  1.068819  0.964319  0.895219  0.790473  0.720885   \n",
              "  1   0.825876  0.881314  0.818073  0.674205  0.546963  0.485933  0.375458   \n",
              "  2   2.132830  2.029373  1.940484  1.852180  1.799809  1.696186  1.610549   \n",
              "  3   0.874412  0.923000  0.964207  0.944243  0.811593  0.663741  0.516367   \n",
              "  4   0.972615  1.112579  1.183380  1.164712  1.028599  0.909215  0.851048   \n",
              "  5   0.673850  0.747933  0.758190  0.635940  0.582957  0.464061  0.367681   \n",
              "  6   2.012730  1.938014  1.927147  1.855045  1.784121  1.714419  1.666451   \n",
              "  7   0.631517  0.662534  0.597692  0.546006  0.547606  0.436211  0.348109   \n",
              "  8   2.096184  2.093218  2.056382  2.021581  1.917125  1.829289  1.706779   \n",
              "  9   1.790156  1.795058  1.775741  1.734943  1.630240  1.528516  1.446278   \n",
              "  10  2.505526  2.478703  2.454693  2.433544  2.421046  2.367274  2.276931   \n",
              "  11  0.127157  0.122243  0.046585 -0.028615 -0.065844 -0.178277 -0.252424   \n",
              "  12  2.078076  2.011625  1.908125  1.749651  1.632047  1.515401  1.399785   \n",
              "  13  1.021168  1.022791  0.988231  0.992590  0.964530  0.972570  0.944914   \n",
              "  14  2.229429  2.105229  1.980304  1.858436  1.737539  1.641465  1.497737   \n",
              "  15  2.290247  2.289725  2.250637  2.171518  2.094044  1.975080  1.889381   \n",
              "  16  1.504078  1.489715  1.404499  1.280276  1.115996  0.976599  0.870025   \n",
              "  17  2.141602  2.151569  2.035135  1.908063  1.749864  1.592447  1.435899   \n",
              "  18  1.920344  1.925599  1.850546  1.776972  1.660807  1.545209  1.435328   \n",
              "  19  1.401658  1.368496  1.248251  1.091195  0.931061  0.807521  0.647330   \n",
              "  \n",
              "          att8      att9     att10  ...    att504    att505    att506    att507  \\\n",
              "  0   0.688010  0.587988  0.518494  ...  0.650269  0.718853  0.805717  0.865237   \n",
              "  1   0.265118  0.154929  0.044902  ... -0.093108 -0.001327  0.084480  0.192384   \n",
              "  2   1.527823  1.439301  1.336817  ...  1.431956  1.531713  1.612717  1.694647   \n",
              "  3   0.352022  0.269166  0.271905  ...  0.226525  0.233978  0.293486  0.360640   \n",
              "  4   0.713570  0.577246  0.445698  ... -0.182151 -0.062613  0.061609  0.187914   \n",
              "  5   0.284874  0.205724  0.130458  ... -0.099778 -0.018597  0.089958  0.147814   \n",
              "  6   1.643602  1.578201  1.491590  ...  1.142339  1.248952  1.355644  1.430132   \n",
              "  7   0.308065  0.207857  0.146228  ... -0.058249 -0.007770  0.076688  0.161348   \n",
              "  8   1.600523  1.512683  1.441550  ...  1.312859  1.413897  1.478759  1.602849   \n",
              "  9   1.347786  1.266135  1.169859  ...  0.871514  0.967446  1.097476  1.204302   \n",
              "  10  2.263223  2.213012  2.164049  ...  1.961736  2.083535  2.151606  2.233325   \n",
              "  11 -0.364820 -0.477208 -0.589589  ... -0.687484 -0.575815 -0.464072 -0.352268   \n",
              "  12  1.274943  1.161114  1.006520  ...  1.129136  1.249304  1.357560  1.509740   \n",
              "  13  0.918908  0.894589  0.871983  ...  0.394486  0.387390  0.460805  0.537175   \n",
              "  14  1.379431  1.260086  1.143555  ...  1.757527  1.858548  1.989787  2.065941   \n",
              "  15  1.740513  1.625066  1.466561  ...  1.481244  1.589360  1.698163  1.811836   \n",
              "  16  0.697800  0.558400  0.451829  ...  0.287177  0.431158  0.536725  0.675695   \n",
              "  17  1.280314  1.156610  1.019460  ...  0.997850  1.104756  1.221656  1.296060   \n",
              "  18  1.315876  1.208370  1.096042  ...  0.918363  0.966153  1.086323  1.203729   \n",
              "  19  0.523918  0.363672  0.240412  ...  0.272943  0.392787  0.513116  0.633888   \n",
              "  \n",
              "        att508    att509    att510    att511    att512  target  \n",
              "  0   0.956820  1.057206  1.126484  1.221802  1.286670    b'1'  \n",
              "  1   0.321336  0.450300  0.558373  0.646437  0.755256    b'1'  \n",
              "  2   1.796306  1.879709  1.962100  2.063447  2.149849    b'1'  \n",
              "  3   0.425044  0.586582  0.610465  0.679952  0.801962    b'1'  \n",
              "  4   0.316121  0.446066  0.577601  0.707684  0.838184    b'1'  \n",
              "  5   0.232875  0.341713  0.427932  0.494586  0.583780    b'1'  \n",
              "  6   1.505788  1.582570  1.720383  1.858580  1.935148    b'1'  \n",
              "  7   0.246194  0.338614  0.424046  0.517889  0.574119    b'1'  \n",
              "  8   1.690343  1.777849  1.879936  1.946079  2.028446    b'1'  \n",
              "  9   1.300090  1.395901  1.479162  1.609820  1.705530    b'1'  \n",
              "  10  2.302562  2.372593  2.390667  2.462546  2.483262    b'2'  \n",
              "  11 -0.273653 -0.199176 -0.087414  0.024401  0.095426    b'2'  \n",
              "  12  1.620433  1.732363  1.814409  1.928421  2.043454    b'2'  \n",
              "  13  0.649521  0.724421  0.836778  0.949139  0.984411    b'2'  \n",
              "  14  2.199836  2.279793  2.334980  2.297313  2.262111    b'2'  \n",
              "  15  1.888481  1.970986  2.055049  2.140595  2.227558    b'2'  \n",
              "  16  0.842464  0.981387  1.120344  1.253769  1.426056    b'2'  \n",
              "  17  1.434989  1.595335  1.724058  1.885459  2.047371    b'2'  \n",
              "  18  1.321662  1.440084  1.557756  1.637236  1.797920    b'2'  \n",
              "  19  0.795240  0.915774  1.037277  1.197026  1.317564    b'2'  \n",
              "  \n",
              "  [20 rows x 513 columns],\n",
              "  'test':         att1      att2      att3      att4      att5      att6      att7  \\\n",
              "  0   1.740087  1.733105  1.709192  1.633330  1.540576  1.451067  1.355961   \n",
              "  1   1.679211  1.737285  1.813327  1.793709  1.733931  1.625368  1.516802   \n",
              "  2   0.100879  0.170419  0.267467  0.288188  0.172144  0.090526  0.012875   \n",
              "  3   1.996238  2.054404  2.080863  2.034470  1.989211  1.879904  1.792061   \n",
              "  4   0.948071  0.977192  0.924293  0.861870  0.751602  0.654568  0.544164   \n",
              "  5   0.525850  0.542466  0.505904  0.485558  0.453859  0.332880  0.244524   \n",
              "  6   1.885183  1.932595  1.864414  1.777030  1.671333  1.534653  1.411039   \n",
              "  7   0.525445  0.624924  0.659965  0.600010  0.522889  0.449194  0.340186   \n",
              "  8   1.824968  1.845391  1.868061  1.892944  1.826850  1.781362  1.745975   \n",
              "  9   0.223018  0.289370  0.221031  0.211848  0.285642  0.200785  0.139573   \n",
              "  10  1.946282  1.876617  1.744540  1.645420  1.513365  1.414881  1.316994   \n",
              "  11  2.408040  2.377380  2.348261  2.289352  2.198860  2.140373  2.085261   \n",
              "  12  1.874436  1.768047  1.684686  1.582798  1.478919  1.400798  1.305821   \n",
              "  13  1.375724  1.411288  1.339461  1.241872  1.110240  1.092327  1.076815   \n",
              "  14  1.461889  1.476455  1.460916  1.319950  1.170598  1.057070  0.885315   \n",
              "  15  1.886873  1.928828  1.840890  1.754675  1.625816  1.587736  1.507183   \n",
              "  16  1.699308  1.714787  1.732271  1.751745  1.651546  1.551433  1.573736   \n",
              "  17  1.556693  1.619796  1.703521  1.774216  1.798254  1.794212  1.773299   \n",
              "  18  1.629116  1.542285  1.438881  1.317801  1.179601  1.058845  0.922054   \n",
              "  19  2.134566  2.170490  2.161822  2.144872  2.091225  1.977069  1.976471   \n",
              "  \n",
              "          att8      att9     att10  ...    att504    att505    att506    att507  \\\n",
              "  0   1.285267  1.179863  1.078374  ...  0.816321  0.917592  1.029331  1.135897   \n",
              "  1   1.408236  1.316193  1.207624  ...  0.788859  0.869957  0.965391  1.047022   \n",
              "  2  -0.071698 -0.181847 -0.266307  ... -0.651867 -0.562965 -0.490732 -0.417542   \n",
              "  3   1.682821  1.573700  1.519189  ...  1.161921  1.285527  1.373899  1.445119   \n",
              "  4   0.422082  0.336781  0.226582  ...  0.051135  0.143254  0.227250  0.340028   \n",
              "  5   0.138106  0.001028 -0.105261  ... -0.555469 -0.448479 -0.329940 -0.222978   \n",
              "  6   1.345772  1.240406  1.118674  ...  1.249962  1.387271  1.470585  1.512399   \n",
              "  7   0.305349  0.219597  0.147609  ... -0.269040 -0.200366 -0.107549 -0.014351   \n",
              "  8   1.664544  1.570614  1.558551  ...  0.987072  1.078937  1.182910  1.286995   \n",
              "  9   0.062779 -0.020132 -0.081552  ... -0.457535 -0.377966 -0.314885 -0.235291   \n",
              "  10  1.220114  1.157065  1.062385  ...  0.955956  1.022565  1.122925  1.224179   \n",
              "  11  1.997533  1.907313  1.821009  ...  1.654999  1.779531  1.901049  1.989056   \n",
              "  12  1.199682  1.126758  1.030019  ...  1.571623  1.699151  1.783178  1.891549   \n",
              "  13  0.933555  0.743372  0.667169  ...  0.787690  0.843505  0.905585  1.011304   \n",
              "  14  0.739283  0.582863  0.450985  ...  0.327338  0.461070  0.594992  0.753990   \n",
              "  15  1.388273  1.310944  1.235864  ...  0.862745  0.960283  1.055939  1.170554   \n",
              "  16  1.535975  1.498991  1.400065  ...  1.241746  1.294838  1.348442  1.402536   \n",
              "  17  1.724731  1.606943  1.461844  ...  0.631045  0.745685  0.872319  0.965148   \n",
              "  18  0.801716  0.666578  0.513335  ...  0.595558  0.721285  0.848944  0.978364   \n",
              "  19  1.914292  1.815527  1.703638  ...  1.437182  1.525007  1.608863  1.698110   \n",
              "  \n",
              "        att508    att509    att510    att511    att512  target  \n",
              "  0   1.248002  1.336821  1.443465  1.550141  1.662512    b'1'  \n",
              "  1   1.155178  1.263358  1.357037  1.477295  1.597773    b'1'  \n",
              "  2  -0.330502 -0.235776 -0.148947 -0.052246  0.024020    b'1'  \n",
              "  3   1.568587  1.640186  1.728535  1.835455  1.888998    b'1'  \n",
              "  4   0.452995  0.574455  0.658332  0.742317  0.863935    b'1'  \n",
              "  5  -0.116009  0.022765  0.141379  0.280091  0.407483    b'1'  \n",
              "  6   1.545800  1.591037  1.674099  1.767471  1.809054    b'1'  \n",
              "  7   0.079558  0.174114  0.266836  0.361917  0.454583    b'1'  \n",
              "  8   1.391180  1.466190  1.586982  1.658699  1.763288    b'1'  \n",
              "  9  -0.148866 -0.085691 -0.006228  0.073315  0.143666    b'1'  \n",
              "  10  1.326267  1.459367  1.559894  1.723374  1.886887    b'2'  \n",
              "  11  2.111413  2.202828  2.292607  2.351888  2.378664    b'2'  \n",
              "  12  1.973260  2.054492  2.051440  2.005479  1.938868    b'2'  \n",
              "  13  1.028508  1.092570  1.208310  1.225596  1.304606    b'2'  \n",
              "  14  0.903922  1.054660  1.172247  1.282937  1.362534    b'2'  \n",
              "  15  1.285169  1.409019  1.523624  1.647804  1.782557    b'2'  \n",
              "  16  1.457117  1.512153  1.567644  1.629064  1.635085    b'2'  \n",
              "  17  1.058416  1.165385  1.293342  1.368613  1.478576    b'2'  \n",
              "  18  1.096934  1.228478  1.380949  1.481099  1.615704    b'2'  \n",
              "  19  1.782540  1.873087  1.925184  2.017472  2.079197    b'2'  \n",
              "  \n",
              "  [20 rows x 513 columns]},\n",
              " 'DodgerLoopGame': {'train':     att1  att2  att3  att4  att5  att6  att7  att8  att9  att10  ...  att280  \\\n",
              "  0    7.0   3.0   6.0  11.0   8.0   6.0   6.0  10.0   4.0    7.0  ...     5.0   \n",
              "  1    9.0  10.0   5.0   7.0  10.0   9.0   5.0   6.0   8.0    3.0  ...     5.0   \n",
              "  2   12.0  18.0  11.0  11.0  19.0  17.0   4.0   6.0   8.0   12.0  ...     9.0   \n",
              "  3   11.0   9.0  11.0  12.0   8.0   8.0   5.0   8.0   8.0   12.0  ...    16.0   \n",
              "  4   12.0   9.0  11.0   7.0  12.0  14.0  10.0  10.0  10.0    6.0  ...     7.0   \n",
              "  5    9.0   5.0   6.0   4.0   4.0   7.0   4.0   5.0   6.0    2.0  ...     7.0   \n",
              "  6    7.0   4.0   3.0   5.0   4.0   2.0   8.0   5.0   8.0    3.0  ...     7.0   \n",
              "  7    9.0   5.0   1.0   4.0   2.0   6.0   7.0   2.0   7.0    3.0  ...    12.0   \n",
              "  8   10.0   7.0  14.0   5.0   7.0  10.0   8.0   9.0   8.0    9.0  ...    26.0   \n",
              "  9    7.0   5.0   3.0   6.0   8.0   5.0   1.0   8.0   4.0    9.0  ...    12.0   \n",
              "  10  16.0  20.0  14.0  14.0   9.0  11.0  13.0   7.0   8.0    7.0  ...    17.0   \n",
              "  11   9.0   6.0  15.0  10.0  12.0  11.0  20.0  24.0  11.0   13.0  ...    24.0   \n",
              "  12  19.0  10.0  15.0  11.0  11.0   5.0   6.0   9.0   7.0    4.0  ...    27.0   \n",
              "  13   3.0  10.0   3.0   5.0   1.0   4.0   6.0   4.0   6.0    4.0  ...    13.0   \n",
              "  14  10.0   9.0   7.0   4.0   4.0   7.0   4.0   3.0   6.0    3.0  ...     7.0   \n",
              "  15   5.0   4.0   6.0   8.0   2.0   4.0   6.0   2.0   1.0    3.0  ...    13.0   \n",
              "  16   6.0   3.0   6.0   4.0   8.0   5.0   2.0   8.0   2.0    4.0  ...    44.0   \n",
              "  17  16.0  15.0  13.0  14.0   8.0  16.0  14.0   9.0   9.0    8.0  ...    11.0   \n",
              "  18   7.0   7.0   6.0   6.0   8.0   7.0   9.0   4.0   8.0    4.0  ...    33.0   \n",
              "  19   7.0   5.0   5.0   5.0   0.0   5.0   1.0   7.0   7.0    2.0  ...     9.0   \n",
              "  \n",
              "      att281  att282  att283  att284  att285  att286  att287  att288  target  \n",
              "  0      9.0     4.0     4.0     6.0     9.0     5.0    16.0     8.0    b'1'  \n",
              "  1      4.0     8.0     6.0    11.0     5.0     8.0     9.0     6.0    b'1'  \n",
              "  2     11.0     8.0     4.0     7.0     3.0     6.0     3.0     6.0    b'1'  \n",
              "  3     10.0     7.0    10.0    11.0    12.0    13.0     7.0    10.0    b'1'  \n",
              "  4      9.0    11.0     6.0     9.0     7.0    10.0     4.0     9.0    b'1'  \n",
              "  5      4.0    10.0     8.0     6.0     2.0     2.0     4.0     9.0    b'1'  \n",
              "  6      6.0     8.0     5.0     2.0    10.0     5.0     8.0     6.0    b'1'  \n",
              "  7      9.0    12.0    18.0    10.0    17.0     9.0    15.0    10.0    b'1'  \n",
              "  8     23.0    20.0    22.0    14.0    21.0    18.0     8.0    15.0    b'1'  \n",
              "  9     11.0    11.0    11.0     3.0    13.0     7.0    14.0     6.0    b'1'  \n",
              "  10    20.0    19.0    24.0    11.0    18.0    12.0    12.0    18.0    b'2'  \n",
              "  11    35.0    32.0    15.0    18.0    18.0    16.0    13.0    11.0    b'2'  \n",
              "  12    18.0    19.0    21.0    22.0    19.0    21.0    14.0    23.0    b'2'  \n",
              "  13    10.0     8.0    15.0     7.0     1.0     4.0     9.0     2.0    b'2'  \n",
              "  14     9.0     9.0     6.0     7.0     3.0     7.0     6.0     8.0    b'2'  \n",
              "  15    17.0    11.0    11.0    11.0    12.0     8.0     3.0     6.0    b'2'  \n",
              "  16    49.0    40.0    30.0    20.0    17.0    17.0     9.0    13.0    b'2'  \n",
              "  17     6.0     3.0    11.0     9.0     2.0     6.0     6.0     3.0    b'2'  \n",
              "  18    41.0    46.0    23.0    23.0    19.0    16.0    16.0    11.0    b'2'  \n",
              "  19     8.0     6.0     7.0     6.0     7.0     7.0    10.0     7.0    b'2'  \n",
              "  \n",
              "  [20 rows x 289 columns],\n",
              "  'test':      att1  att2  att3  att4  att5  att6  att7  att8  att9  att10  ...  att280  \\\n",
              "  0     2.0   8.0   7.0   6.0   2.0   8.0   5.0  10.0   3.0    6.0  ...     7.0   \n",
              "  1     8.0   5.0  10.0  11.0   9.0  10.0   7.0  18.0  11.0    8.0  ...     7.0   \n",
              "  2     1.0   9.0   5.0   2.0   5.0   5.0   5.0  13.0   6.0    4.0  ...     5.0   \n",
              "  3     2.0   6.0   6.0   3.0   8.0   6.0   3.0   4.0   3.0    4.0  ...    13.0   \n",
              "  4     8.0   6.0   5.0  11.0   7.0   4.0  10.0   8.0   8.0    4.0  ...    13.0   \n",
              "  ..    ...   ...   ...   ...   ...   ...   ...   ...   ...    ...  ...     ...   \n",
              "  133  17.0  11.0   9.0  16.0  10.0   4.0  10.0  13.0   7.0   11.0  ...     9.0   \n",
              "  134  18.0  12.0  14.0  13.0   8.0   7.0   7.0   6.0  13.0    8.0  ...    24.0   \n",
              "  135   7.0   6.0   5.0   4.0   6.0   3.0   8.0   4.0   5.0    8.0  ...     9.0   \n",
              "  136  14.0  10.0  10.0   7.0  10.0   5.0  11.0   9.0  11.0    9.0  ...     4.0   \n",
              "  137   8.0   8.0   4.0   5.0   5.0   8.0   3.0   6.0   6.0    2.0  ...     8.0   \n",
              "  \n",
              "       att281  att282  att283  att284  att285  att286  att287  att288  target  \n",
              "  0      12.0     4.0     9.0    13.0     3.0     5.0     5.0     3.0    b'1'  \n",
              "  1       6.0     7.0     1.0     2.0     6.0     7.0     8.0     6.0    b'1'  \n",
              "  2      14.0     9.0    13.0    10.0     9.0     5.0    11.0     6.0    b'1'  \n",
              "  3       9.0    11.0    10.0     4.0     6.0     6.0     3.0    10.0    b'1'  \n",
              "  4      15.0    17.0    10.0     8.0    12.0    16.0    15.0    13.0    b'1'  \n",
              "  ..      ...     ...     ...     ...     ...     ...     ...     ...     ...  \n",
              "  133    12.0     4.0     5.0     4.0    10.0     6.0     4.0     3.0    b'2'  \n",
              "  134    11.0    20.0    28.0    20.0    22.0    19.0    16.0    24.0    b'2'  \n",
              "  135     7.0     9.0    11.0     9.0    12.0     6.0     5.0     6.0    b'2'  \n",
              "  136     9.0     2.0    15.0     7.0    12.0     3.0     6.0     6.0    b'2'  \n",
              "  137     9.0    10.0     5.0     5.0     8.0    11.0     8.0     4.0    b'2'  \n",
              "  \n",
              "  [138 rows x 289 columns]},\n",
              " 'GunPoint': {'train':         att1      att2      att3      att4      att5      att6      att7  \\\n",
              "  0  -0.647885 -0.641992 -0.638186 -0.638259 -0.638345 -0.638697 -0.643049   \n",
              "  1  -0.644427 -0.645401 -0.647055 -0.647492 -0.646910 -0.643884 -0.639731   \n",
              "  2  -0.778353 -0.778279 -0.777151 -0.777684 -0.775900 -0.772421 -0.765464   \n",
              "  3  -0.750060 -0.748103 -0.746164 -0.745926 -0.743767 -0.743805 -0.745213   \n",
              "  4  -0.599539 -0.597422 -0.599269 -0.598259 -0.597582 -0.591303 -0.589020   \n",
              "  5  -0.547736 -0.553660 -0.557194 -0.559599 -0.564312 -0.568220 -0.571968   \n",
              "  6  -1.261183 -1.294884 -1.310105 -1.319604 -1.320262 -1.317001 -1.309626   \n",
              "  7  -2.012581 -2.012069 -2.011625 -2.013534 -2.013438 -2.013219 -2.014245   \n",
              "  8  -1.065573 -1.066501 -1.067219 -1.068197 -1.067617 -1.071252 -1.067488   \n",
              "  9  -1.177206 -1.175839 -1.173185 -1.170890 -1.169488 -1.166309 -1.165919   \n",
              "  10 -0.816323 -0.814104 -0.815892 -0.814220 -0.816649 -0.816978 -0.811393   \n",
              "  11 -1.136846 -1.140746 -1.139471 -1.130013 -1.121607 -1.118990 -1.112249   \n",
              "  12 -1.115016 -1.186591 -1.263632 -1.341706 -1.385512 -1.406174 -1.396433   \n",
              "  13 -1.201155 -1.208410 -1.206482 -1.203056 -1.180973 -1.165620 -1.164265   \n",
              "  14 -0.603291 -0.607376 -0.606829 -0.607565 -0.604953 -0.596126 -0.590059   \n",
              "  15 -1.162008 -1.161359 -1.162379 -1.164074 -1.161457 -1.157800 -1.159455   \n",
              "  16 -0.808018 -0.809292 -0.808723 -0.805904 -0.803404 -0.801347 -0.798875   \n",
              "  17 -0.622128 -0.619164 -0.613308 -0.611285 -0.607336 -0.607347 -0.607487   \n",
              "  18 -1.054014 -1.050717 -1.047666 -1.047448 -1.048769 -1.047781 -1.047891   \n",
              "  19 -1.082541 -1.082470 -1.084301 -1.083262 -1.084104 -1.085222 -1.083233   \n",
              "  20 -0.851924 -0.849687 -0.850311 -0.848363 -0.845198 -0.839203 -0.834818   \n",
              "  21 -0.769293 -0.772803 -0.767545 -0.753188 -0.738470 -0.721032 -0.700963   \n",
              "  22 -1.238278 -1.186778 -1.147941 -1.125283 -1.125837 -1.129168 -1.135536   \n",
              "  23 -1.755800 -1.746496 -1.732612 -1.727370 -1.725305 -1.724826 -1.721212   \n",
              "  24 -0.716838 -0.713062 -0.710098 -0.711421 -0.709967 -0.711136 -0.708688   \n",
              "  25 -0.969391 -0.972108 -0.972616 -0.973649 -0.973924 -0.976987 -0.976895   \n",
              "  26 -0.971732 -1.012182 -1.049772 -1.077144 -1.092190 -1.092920 -1.090993   \n",
              "  27 -1.081020 -1.078859 -1.079472 -1.080085 -1.078681 -1.078272 -1.077298   \n",
              "  28 -1.006849 -1.008827 -1.008523 -1.011347 -1.011705 -1.011933 -1.014436   \n",
              "  29 -1.441403 -1.504756 -1.553785 -1.566228 -1.550400 -1.505409 -1.454040   \n",
              "  30 -0.964333 -0.964264 -0.964772 -0.963092 -0.963757 -0.962386 -0.961999   \n",
              "  31 -1.481718 -1.482924 -1.483160 -1.482303 -1.479985 -1.480745 -1.481513   \n",
              "  32 -0.981131 -0.979102 -0.977645 -0.975884 -0.975598 -0.977514 -0.977998   \n",
              "  33 -0.723961 -0.725263 -0.729254 -0.732690 -0.733603 -0.734398 -0.736329   \n",
              "  34 -0.644121 -0.641005 -0.639447 -0.636397 -0.635603 -0.632853 -0.631492   \n",
              "  35 -0.604468 -0.608084 -0.613065 -0.614926 -0.615522 -0.616300 -0.617992   \n",
              "  36 -1.287009 -1.282432 -1.303656 -1.293082 -1.293506 -1.292730 -1.299701   \n",
              "  37 -0.546345 -0.548584 -0.549649 -0.549325 -0.550956 -0.556537 -0.556732   \n",
              "  38 -1.623368 -1.623696 -1.622161 -1.622906 -1.621739 -1.621860 -1.622854   \n",
              "  39 -1.113247 -1.113157 -1.114343 -1.113907 -1.115143 -1.117166 -1.115657   \n",
              "  40 -0.744119 -0.734262 -0.730512 -0.721463 -0.708476 -0.699061 -0.695946   \n",
              "  41 -1.153652 -1.150899 -1.150287 -1.149413 -1.149148 -1.147418 -1.147949   \n",
              "  42 -0.969865 -0.972680 -0.970600 -0.971651 -0.968887 -0.967290 -0.965224   \n",
              "  43 -1.160162 -1.243003 -1.254295 -1.234512 -1.166222 -1.096319 -1.039987   \n",
              "  44 -1.036995 -1.037497 -1.037294 -1.037132 -1.040754 -1.040785 -1.040019   \n",
              "  45 -0.564906 -0.565050 -0.566477 -0.564775 -0.565744 -0.564183 -0.564637   \n",
              "  46 -0.614644 -0.614987 -0.614786 -0.614042 -0.613145 -0.612391 -0.610861   \n",
              "  47 -0.779126 -0.778379 -0.775745 -0.776247 -0.773167 -0.773882 -0.768961   \n",
              "  48 -0.703033 -0.702618 -0.702504 -0.701361 -0.700449 -0.700562 -0.700974   \n",
              "  49 -1.435720 -1.432272 -1.432929 -1.431641 -1.432595 -1.432303 -1.433452   \n",
              "  \n",
              "          att8      att9     att10  ...    att142    att143    att144    att145  \\\n",
              "  0  -0.643768 -0.645050 -0.647118  ... -0.639716 -0.639735 -0.640184 -0.639235   \n",
              "  1  -0.638094 -0.635297 -0.635384  ... -0.641426 -0.639267 -0.637797 -0.637680   \n",
              "  2  -0.762275 -0.763752 -0.765356  ... -0.718712 -0.713534 -0.710021 -0.704126   \n",
              "  3  -0.745082 -0.745727 -0.745815  ... -0.724661 -0.729229 -0.728940 -0.727834   \n",
              "  4  -0.587533 -0.585462 -0.583847  ... -0.643885 -0.645742 -0.646458 -0.646464   \n",
              "  5  -0.575826 -0.577354 -0.580818  ... -0.704759 -0.703900 -0.704163 -0.705410   \n",
              "  6  -1.296729 -1.284765 -1.280137  ... -1.269225 -1.274458 -1.278982 -1.280090   \n",
              "  7  -2.012278 -2.014058 -2.013003  ...  0.360089  0.274340  0.163402  0.019592   \n",
              "  8  -1.067816 -1.067875 -1.069818  ... -1.046511 -1.048871 -1.046295 -1.046580   \n",
              "  9  -1.167642 -1.166901 -1.168441  ... -1.295701 -1.327421 -1.327071 -1.300439   \n",
              "  10 -0.811339 -0.812096 -0.813699  ... -1.028066 -1.021606 -1.021195 -1.024795   \n",
              "  11 -1.113174 -1.115731 -1.114752  ... -1.154958 -1.130243 -1.118832 -1.122127   \n",
              "  12 -1.338130 -1.306990 -1.312580  ... -0.995515 -0.996563 -0.998444 -1.001865   \n",
              "  13 -1.168617 -1.163736 -1.164060  ... -1.165393 -1.272919 -1.343542 -1.337689   \n",
              "  14 -0.586220 -0.583763 -0.583080  ... -0.594511 -0.595603 -0.603554 -0.612209   \n",
              "  15 -1.161424 -1.158713 -1.161589  ... -1.136727 -1.137836 -1.132538 -1.129391   \n",
              "  16 -0.794809 -0.791848 -0.790466  ... -0.695277 -0.690663 -0.690106 -0.685703   \n",
              "  17 -0.606411 -0.606287 -0.609101  ... -0.595359 -0.598823 -0.603955 -0.609916   \n",
              "  18 -1.047536 -1.047369 -1.044656  ... -1.071515 -1.063564 -1.066977 -1.071325   \n",
              "  19 -1.083495 -1.083226 -1.084807  ... -1.146026 -1.145903 -1.147187 -1.145955   \n",
              "  20 -0.834412 -0.834664 -0.833264  ... -0.881958 -0.871798 -0.861634 -0.845883   \n",
              "  21 -0.685223 -0.671344 -0.670161  ... -1.025212 -1.014792 -1.006514 -1.003012   \n",
              "  22 -1.139822 -1.132811 -1.127346  ... -1.112665 -1.182298 -1.252019 -1.319470   \n",
              "  23 -1.722971 -1.718352 -1.720910  ... -1.051389 -1.275793 -1.470041 -1.639795   \n",
              "  24 -0.708387 -0.708409 -0.709050  ... -0.558172 -0.562053 -0.567406 -0.569266   \n",
              "  25 -0.977544 -0.979135 -0.978516  ... -0.924728 -0.922734 -0.924245 -0.923938   \n",
              "  26 -1.083252 -1.074275 -1.070387  ... -1.239248 -1.200457 -1.170905 -1.158130   \n",
              "  27 -1.078944 -1.077041 -1.078412  ... -1.202613 -1.203260 -1.200616 -1.196168   \n",
              "  28 -1.012562 -1.017186 -1.018407  ... -1.114498 -1.117535 -1.119042 -1.120056   \n",
              "  29 -1.408540 -1.375772 -1.367858  ... -1.141934 -1.150923 -1.155292 -1.157989   \n",
              "  30 -0.961540 -0.960973 -0.955632  ... -0.893666 -0.891841 -0.893301 -0.891128   \n",
              "  31 -1.480230 -1.481170 -1.480936  ... -1.362261 -1.363540 -1.364604 -1.368324   \n",
              "  32 -0.979422 -0.980816 -0.980945  ... -0.971827 -0.970183 -0.965389 -0.965832   \n",
              "  33 -0.738404 -0.740447 -0.745410  ... -0.756425 -0.755322 -0.757650 -0.760134   \n",
              "  34 -0.628741 -0.625365 -0.620119  ... -0.619075 -0.618718 -0.614866 -0.614519   \n",
              "  35 -0.618821 -0.619901 -0.620865  ... -0.647263 -0.646744 -0.645072 -0.643929   \n",
              "  36 -1.302802 -1.299218 -1.305025  ... -1.197890 -1.197334 -1.197650 -1.197966   \n",
              "  37 -0.562642 -0.564610 -0.567597  ... -0.665614 -0.659891 -0.656913 -0.654146   \n",
              "  38 -1.621253 -1.622584 -1.622030  ... -1.549479 -1.660080 -1.745874 -1.797701   \n",
              "  39 -1.117199 -1.118094 -1.117937  ... -1.173644 -1.174277 -1.175176 -1.176694   \n",
              "  40 -0.693064 -0.693325 -0.693232  ... -0.711650 -0.711025 -0.711942 -0.708887   \n",
              "  41 -1.143553 -1.145072 -1.145133  ... -0.999805 -1.074357 -1.160415 -1.230090   \n",
              "  42 -0.964983 -0.964252 -0.961067  ... -1.015520 -1.014679 -1.011770 -1.006992   \n",
              "  43 -1.026723 -1.033920 -1.047347  ... -1.221131 -1.180033 -1.121479 -1.083692   \n",
              "  44 -1.038676 -1.039535 -1.040101  ... -1.147545 -1.149843 -1.151544 -1.152749   \n",
              "  45 -0.563114 -0.564548 -0.562195  ... -0.725717 -0.726697 -0.725656 -0.726813   \n",
              "  46 -0.608124 -0.606101 -0.603111  ... -0.784714 -0.796625 -0.804653 -0.800372   \n",
              "  47 -0.762046 -0.758626 -0.755583  ... -0.512710 -0.510124 -0.511867 -0.511880   \n",
              "  48 -0.701128 -0.702176 -0.701769  ... -0.640705 -0.639800 -0.639546 -0.637827   \n",
              "  49 -1.432427 -1.433273 -1.429953  ... -1.461869 -1.447364 -1.438888 -1.437793   \n",
              "  \n",
              "        att146    att147    att148    att149    att150  target  \n",
              "  0  -0.639395 -0.640231 -0.640429 -0.638666 -0.638657    b'2'  \n",
              "  1  -0.635260 -0.635490 -0.634934 -0.634497 -0.631596    b'2'  \n",
              "  2  -0.703263 -0.703393 -0.704196 -0.707605 -0.707120    b'1'  \n",
              "  3  -0.728244 -0.726453 -0.725517 -0.725191 -0.724679    b'1'  \n",
              "  4  -0.645585 -0.642412 -0.643337 -0.636803 -0.631716    b'2'  \n",
              "  5  -0.705741 -0.703861 -0.706541 -0.710381 -0.710854    b'2'  \n",
              "  6  -1.281349 -1.281277 -1.280616 -1.280212 -1.279940    b'2'  \n",
              "  7  -0.150113 -0.333859 -0.551477 -0.782467 -1.007992    b'2'  \n",
              "  8  -1.038032 -1.037612 -1.033426 -1.031462 -1.030165    b'2'  \n",
              "  9  -1.271138 -1.267283 -1.265006 -1.270722 -1.262134    b'1'  \n",
              "  10 -1.021716 -1.022889 -1.021380 -1.022272 -1.022983    b'1'  \n",
              "  11 -1.124086 -1.120237 -1.111846 -1.103578 -1.103998    b'1'  \n",
              "  12 -1.007205 -1.012854 -1.021305 -1.029152 -1.044706    b'1'  \n",
              "  13 -1.336491 -1.284089 -1.206961 -1.122139 -1.082205    b'1'  \n",
              "  14 -0.623519 -0.625307 -0.625411 -0.614697 -0.604779    b'2'  \n",
              "  15 -1.128199 -1.128224 -1.125779 -1.121353 -1.116188    b'1'  \n",
              "  16 -0.680779 -0.676761 -0.673248 -0.668439 -0.663304    b'2'  \n",
              "  17 -0.615390 -0.624009 -0.628865 -0.640098 -0.650745    b'2'  \n",
              "  18 -1.068112 -1.068966 -1.069154 -1.066642 -1.064798    b'1'  \n",
              "  19 -1.148524 -1.149558 -1.148339 -1.149799 -1.148310    b'2'  \n",
              "  20 -0.837268 -0.819175 -0.812857 -0.805104 -0.802605    b'1'  \n",
              "  21 -1.000901 -1.001019 -0.997393 -0.996212 -0.994838    b'1'  \n",
              "  22 -1.329326 -1.334852 -1.299284 -1.246920 -1.213891    b'1'  \n",
              "  23 -1.757432 -1.826076 -1.870268 -1.894537 -1.898637    b'2'  \n",
              "  24 -0.572434 -0.571733 -0.570443 -0.569006 -0.566393    b'1'  \n",
              "  25 -0.923793 -0.924096 -0.925417 -0.926572 -0.929978    b'2'  \n",
              "  26 -1.153122 -1.154176 -1.154564 -1.150073 -1.145040    b'1'  \n",
              "  27 -1.199188 -1.195577 -1.186975 -1.173823 -1.166574    b'1'  \n",
              "  28 -1.120553 -1.120983 -1.122364 -1.121879 -1.122235    b'2'  \n",
              "  29 -1.162612 -1.165037 -1.170046 -1.174333 -1.174406    b'1'  \n",
              "  30 -0.890467 -0.889976 -0.890854 -0.890339 -0.893748    b'1'  \n",
              "  31 -1.370659 -1.374070 -1.373879 -1.373785 -1.374736    b'2'  \n",
              "  32 -0.966595 -0.967407 -0.969254 -0.970416 -0.970535    b'2'  \n",
              "  33 -0.757973 -0.753264 -0.751725 -0.749770 -0.744602    b'1'  \n",
              "  34 -0.609214 -0.607610 -0.604666 -0.605630 -0.600113    b'2'  \n",
              "  35 -0.642893 -0.642514 -0.640783 -0.640529 -0.640211    b'1'  \n",
              "  36 -1.198309 -1.199803 -1.202034 -1.203569 -1.205487    b'2'  \n",
              "  37 -0.652727 -0.651819 -0.651962 -0.651519 -0.653748    b'2'  \n",
              "  38 -1.821457 -1.820755 -1.814826 -1.802348 -1.779259    b'2'  \n",
              "  39 -1.175051 -1.176095 -1.175167 -1.174964 -1.174871    b'2'  \n",
              "  40 -0.706704 -0.706233 -0.704465 -0.704567 -0.703899    b'2'  \n",
              "  41 -1.262929 -1.260485 -1.237534 -1.213591 -1.196872    b'1'  \n",
              "  42 -1.003574 -1.006509 -1.006429 -1.006552 -1.003153    b'1'  \n",
              "  43 -1.053213 -1.038400 -1.034783 -1.038866 -1.033090    b'1'  \n",
              "  44 -1.150443 -1.150210 -1.152899 -1.150172 -1.151864    b'2'  \n",
              "  45 -0.726768 -0.725525 -0.724171 -0.720889 -0.718832    b'2'  \n",
              "  46 -0.797827 -0.795079 -0.797045 -0.801276 -0.808361    b'1'  \n",
              "  47 -0.507179 -0.506964 -0.505006 -0.503731 -0.504385    b'2'  \n",
              "  48 -0.639201 -0.640260 -0.641134 -0.641406 -0.642109    b'1'  \n",
              "  49 -1.436885 -1.434493 -1.435462 -1.435282 -1.430884    b'2'  \n",
              "  \n",
              "  [50 rows x 151 columns],\n",
              "  'test':          att1      att2      att3      att4      att5      att6      att7  \\\n",
              "  0   -1.125013 -1.131338 -1.138288 -1.146687 -1.138639 -1.141431 -1.143691   \n",
              "  1   -0.626956 -0.625919 -0.627538 -0.626326 -0.624085 -0.624708 -0.625006   \n",
              "  2   -2.001163 -1.999575 -1.999537 -1.999196 -1.999004 -2.000315 -1.998425   \n",
              "  3   -1.004587 -0.999843 -0.995250 -0.992019 -0.991200 -0.987556 -0.996473   \n",
              "  4   -0.742625 -0.743770 -0.743900 -0.744873 -0.744745 -0.745364 -0.747078   \n",
              "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
              "  145 -0.580006 -0.583332 -0.586108 -0.589118 -0.591951 -0.599196 -0.609292   \n",
              "  146 -0.728153 -0.730242 -0.733560 -0.734188 -0.734331 -0.734660 -0.733856   \n",
              "  147 -0.738012 -0.736301 -0.731226 -0.728455 -0.728883 -0.727372 -0.724525   \n",
              "  148 -1.265111 -1.256093 -1.259421 -1.256351 -1.253265 -1.260103 -1.265063   \n",
              "  149 -1.427205 -1.408303 -1.347118 -1.291666 -1.266331 -1.264420 -1.271496   \n",
              "  \n",
              "           att8      att9     att10  ...    att142    att143    att144  \\\n",
              "  0   -1.144379 -1.154912 -1.146421  ... -1.281235 -1.323420 -1.345800   \n",
              "  1   -0.624175 -0.624018 -0.622033  ... -0.621505 -0.621526 -0.624091   \n",
              "  2   -2.000679 -1.999995 -2.000786  ...  0.242217  0.145716  0.014012   \n",
              "  3   -0.996878 -0.998673 -0.997882  ... -1.060166 -1.044471 -1.039528   \n",
              "  4   -0.746615 -0.746705 -0.745859  ... -0.696897 -0.694059 -0.689150   \n",
              "  ..        ...       ...       ...  ...       ...       ...       ...   \n",
              "  145 -0.618504 -0.627164 -0.635995  ... -0.537708 -0.537554 -0.538319   \n",
              "  146 -0.733397 -0.732929 -0.731822  ... -0.768710 -0.748156 -0.728561   \n",
              "  147 -0.720916 -0.719828 -0.719228  ... -0.613856 -0.611590 -0.609785   \n",
              "  148 -1.256396 -1.246350 -1.249132  ... -1.193333 -1.195697 -1.189598   \n",
              "  149 -1.275212 -1.278654 -1.279369  ... -1.032759 -1.039843 -1.046789   \n",
              "  \n",
              "         att145    att146    att147    att148    att149    att150  target  \n",
              "  0   -1.344547 -1.301098 -1.265903 -1.212717 -1.206178 -1.218422    b'1'  \n",
              "  1   -0.623989 -0.624350 -0.624376 -0.619471 -0.612058 -0.606422    b'2'  \n",
              "  2   -0.151780 -0.333427 -0.577435 -0.812720 -1.071147 -1.323383    b'2'  \n",
              "  3   -1.040693 -1.044162 -1.044058 -1.044916 -1.044226 -1.043262    b'1'  \n",
              "  4   -0.687534 -0.682798 -0.682153 -0.681030 -0.670519 -0.657403    b'1'  \n",
              "  ..        ...       ...       ...       ...       ...       ...     ...  \n",
              "  145 -0.538915 -0.541542 -0.545838 -0.546621 -0.548831 -0.553552    b'2'  \n",
              "  146 -0.711126 -0.699604 -0.689584 -0.687476 -0.686448 -0.690183    b'1'  \n",
              "  147 -0.609814 -0.608848 -0.610023 -0.609646 -0.608616 -0.612177    b'2'  \n",
              "  148 -1.177099 -1.188014 -1.189629 -1.199970 -1.193374 -1.192835    b'2'  \n",
              "  149 -1.054712 -1.065305 -1.082951 -1.103461 -1.153119 -1.222043    b'1'  \n",
              "  \n",
              "  [150 rows x 151 columns]},\n",
              " 'SemgHandSubjectCh2': {'train':           att1       att2       att3       att4      att5      att6      att7  \\\n",
              "  0     4.727125   2.797737   3.636139   2.746511  0.971014  2.210892  3.344643   \n",
              "  1     3.710899   2.427400   1.624620   0.835390  1.268488  1.498597  0.799706   \n",
              "  2     3.691784   7.646312   4.573417   6.589344  1.606932  5.105149  3.388973   \n",
              "  3     3.659098   1.348780   2.660728   1.951933  1.336938  2.802475  2.054903   \n",
              "  4     6.352287   3.688895   5.923694   4.516546  3.978157  4.106319  4.735417   \n",
              "  ..         ...        ...        ...        ...       ...       ...       ...   \n",
              "  445   4.553701   4.518896  39.730918  11.080358  5.067545  3.534811  8.533015   \n",
              "  446   2.009192   0.529732   2.845124   2.242986  2.910238  2.858962  1.412370   \n",
              "  447  49.799649  10.666601   6.783201   3.553791  2.337875  2.319299  3.538426   \n",
              "  448   3.941098   2.556127   2.718602   1.410239  3.789492  2.008466  2.932051   \n",
              "  449   2.587807   3.250824   2.364625   5.027626  2.364864  1.588553  4.043644   \n",
              "  \n",
              "           att8      att9     att10  ...    att1492    att1493    att1494  \\\n",
              "  0    0.584697  2.450385  2.185442  ...  10.832140   2.546618  14.407009   \n",
              "  1    1.259650  0.412866  0.928109  ...   2.613174   2.545647   2.449019   \n",
              "  2    6.454872  2.436382  6.159850  ...  16.641788  11.675237  12.064705   \n",
              "  3    2.298930  1.007570  0.718818  ...   2.809517   2.903902   2.703438   \n",
              "  4    5.000411  3.958317  3.482435  ...   2.941040   9.317901  11.762875   \n",
              "  ..        ...       ...       ...  ...        ...        ...        ...   \n",
              "  445  2.201287  4.777182  4.393955  ...  16.904451   2.023173   1.654036   \n",
              "  446  2.816585  2.786106  1.998044  ...   0.851269   3.872917   5.904027   \n",
              "  447  1.209772  0.167166  2.095120  ...  22.607892  11.372765  18.093329   \n",
              "  448  1.650937  1.243658  1.815658  ...  11.654956   9.920663   5.301477   \n",
              "  449  2.403147  0.442368  0.718312  ...  16.839444   1.789912   7.291966   \n",
              "  \n",
              "         att1495    att1496    att1497    att1498    att1499    att1500  target  \n",
              "  0    10.137272   7.191183   3.140133  10.960079  10.386093  19.743019    b'1'  \n",
              "  1     0.674977   2.705351   1.734972   3.257594   4.000138   4.744451    b'1'  \n",
              "  2    39.605277  12.920770   9.888908  17.844828  20.425649   4.004697    b'1'  \n",
              "  3     2.425637   1.168208   2.310419   1.740220   5.439436   1.428443    b'1'  \n",
              "  4    18.062205  13.719079  13.716011   5.139247  14.488791   5.992464    b'1'  \n",
              "  ..         ...        ...        ...        ...        ...        ...     ...  \n",
              "  445   5.094242   4.799647  14.039188   4.418411   7.620376   1.173336    b'5'  \n",
              "  446   4.856691   6.163473   2.698815   7.469406   7.271149  13.621149    b'5'  \n",
              "  447  23.661715  21.392396  12.956776   8.743805   9.839101  31.678746    b'5'  \n",
              "  448  10.273563  13.930936  12.663125   3.643889  39.652621  52.647970    b'5'  \n",
              "  449  15.346520  15.804046   3.048809  11.464140  10.803765  10.560197    b'5'  \n",
              "  \n",
              "  [450 rows x 1501 columns],\n",
              "  'test':          att1      att2       att3      att4      att5      att6      att7  \\\n",
              "  0    1.010492  1.844761   1.994736  1.383945  1.495922  1.038938  0.726807   \n",
              "  1    3.576133  6.759880   6.199223  6.899144  0.698298  5.901366  5.412949   \n",
              "  2    1.427734  3.270781   1.227704  3.372484  1.142124  1.620073  1.835848   \n",
              "  3    4.172805  1.157988   2.305318  2.601001  0.455858  2.023440  1.227672   \n",
              "  4    2.828131  3.639256   2.623337  4.752033  5.136180  2.863516  4.206269   \n",
              "  ..        ...       ...        ...       ...       ...       ...       ...   \n",
              "  445  4.695799  6.326989  29.996944  0.621671  2.375334  0.471384  2.167851   \n",
              "  446  2.856427  0.917944   1.963230  1.737540  0.782542  1.324789  1.494179   \n",
              "  447  2.162179  2.586991   2.943059  1.359064  5.772833  3.044993  6.988667   \n",
              "  448  2.672733  3.618806   2.254437  0.515845  0.420276  0.203551  3.403591   \n",
              "  449  4.808737  8.533683   4.371165  6.997035  4.433613  7.311368  3.430732   \n",
              "  \n",
              "           att8      att9     att10  ...    att1492    att1493    att1494  \\\n",
              "  0    0.517115  0.901956  3.267801  ...   4.514979   3.163670   2.509663   \n",
              "  1    2.242904  1.276969  4.412348  ...   8.212110   7.144221  29.005385   \n",
              "  2    2.137231  1.723264  1.037125  ...   2.822037   0.238614   6.112881   \n",
              "  3    3.436626  2.738081  0.770529  ...   5.205015   6.773116   7.266741   \n",
              "  4    3.726179  6.336589  3.838389  ...   8.443991  12.941081   3.484869   \n",
              "  ..        ...       ...       ...  ...        ...        ...        ...   \n",
              "  445  1.458219  2.775819  3.131145  ...   6.122091  12.350521   7.275547   \n",
              "  446  1.217064  1.841684  1.384750  ...   4.467905   8.853204   7.326494   \n",
              "  447  2.655773  0.949689  4.363189  ...  26.944519  23.372235  30.745837   \n",
              "  448  2.207853  4.098283  3.116977  ...   5.194275   3.840136   2.885063   \n",
              "  449  0.622928  3.200799  4.900171  ...  47.563366  17.124921   9.001127   \n",
              "  \n",
              "         att1495    att1496    att1497    att1498     att1499     att1500  \\\n",
              "  0     3.108228   3.074037   6.149778   4.615355    7.435662   12.169036   \n",
              "  1    17.086162  39.967040  27.415777  39.775845   32.103564   39.307450   \n",
              "  2     9.333081   4.689573  10.574065  10.587818   10.904074    5.766640   \n",
              "  3     8.713474   9.793005   9.217702   8.187921    5.861266   10.991945   \n",
              "  4     8.834546   6.954338  12.287973  19.497624   22.549495    2.601797   \n",
              "  ..         ...        ...        ...        ...         ...         ...   \n",
              "  445   4.374857   0.225396   6.265331   3.019557    2.890066    6.528090   \n",
              "  446   5.399492   9.400727   6.137567   6.331886   16.398597    4.208787   \n",
              "  447  36.807821  19.512118  19.280693  40.984406   48.160525   76.497718   \n",
              "  448  11.631610   2.730871   7.181516   7.566930   13.942657    5.637216   \n",
              "  449  30.875834  67.491631  74.759476  92.726133  114.292690  232.756300   \n",
              "  \n",
              "       target  \n",
              "  0      b'1'  \n",
              "  1      b'1'  \n",
              "  2      b'1'  \n",
              "  3      b'1'  \n",
              "  4      b'1'  \n",
              "  ..      ...  \n",
              "  445    b'5'  \n",
              "  446    b'5'  \n",
              "  447    b'5'  \n",
              "  448    b'5'  \n",
              "  449    b'5'  \n",
              "  \n",
              "  [450 rows x 1501 columns]},\n",
              " 'SwedishLeaf': {'train':          att1     att2      att3      att4      att5      att6      att7  \\\n",
              "  0    1.524750  1.53812  1.410790  1.244400  1.039470  0.868676  0.664257   \n",
              "  1    2.214930  2.05051  1.842350  1.635900  1.432590  1.285370  1.143260   \n",
              "  2    1.872010  1.72637  1.573640  1.396900  1.252210  1.083760  0.955383   \n",
              "  3    1.731019  1.70220  1.553009  1.387209  1.144580  0.951378  0.733035   \n",
              "  4    1.842670  1.74943  1.593560  1.420510  1.268400  1.118720  0.972792   \n",
              "  ..        ...      ...       ...       ...       ...       ...       ...   \n",
              "  495  1.555160  1.39118  1.027670  0.747651  0.425793  0.158014  0.152089   \n",
              "  496  1.823961  1.74961  1.579271  1.384801  1.204190  1.022790  0.876355   \n",
              "  497  2.009910  1.89306  1.711190  1.492730  1.312480  1.097560  0.949675   \n",
              "  498  1.474660  1.49555  1.358110  1.142910  0.906578  0.752583  0.985894   \n",
              "  499  2.021830  1.92956  1.740330  1.581830  1.428630  1.250230  1.103560   \n",
              "  \n",
              "           att8      att9     att10  ...    att120    att121    att122  \\\n",
              "  0    0.489801  0.268549  0.072490  ...  0.760649  0.521033  0.362176   \n",
              "  1    1.006700  0.834105  0.712422  ...  0.712422  0.876184  1.000530   \n",
              "  2    0.796125  0.718198  0.551916  ...  0.660779  0.731471  0.865444   \n",
              "  3    0.559737  0.853391  1.037270  ...  0.102225  0.317060  0.569536   \n",
              "  4    0.832494  0.711975  0.584576  ...  0.635829  0.755926  0.895839   \n",
              "  ..        ...       ...       ...  ...       ...       ...       ...   \n",
              "  495 -0.104332 -0.113924 -0.279057  ...  0.465730  0.150071  0.092285   \n",
              "  496  0.736351  0.632646  0.529009  ...  0.744690  0.836515  0.895575   \n",
              "  497  0.844477  0.782751  0.732888  ...  0.694845  0.753352  0.927181   \n",
              "  498  1.034220  0.868768  0.655180  ...  0.524566  0.764574  1.000560   \n",
              "  499  0.957912  0.795351  0.668549  ...  0.642931  0.794356  0.926149   \n",
              "  \n",
              "         att123    att124    att125   att126   att127    att128  target  \n",
              "  0    0.561489  0.741670  0.955210  1.09676  1.32531  1.484260    b'4'  \n",
              "  1    1.143260  1.339930  1.541850  1.75360  1.96243  2.167350   b'11'  \n",
              "  2    0.978358  1.158070  1.309600  1.49456  1.65084  1.839430   b'13'  \n",
              "  3    0.786314  0.998449  1.217750  1.33880  1.58373  1.688559    b'4'  \n",
              "  4    1.041540  1.188390  1.338390  1.51080  1.66561  1.822640   b'13'  \n",
              "  ..        ...       ...       ...      ...      ...       ...     ...  \n",
              "  495  0.235049  0.392797  0.700363  1.01844  1.32524  1.515870    b'9'  \n",
              "  496  1.026450  1.139960  1.265440  1.44938  1.61830  1.798490   b'12'  \n",
              "  497  1.003640  1.199830  1.372080  1.58494  1.76518  1.976150   b'11'  \n",
              "  498  1.130920  0.986802  0.818025  1.04678  1.28382  1.432340    b'4'  \n",
              "  499  1.086920  1.280660  1.447140  1.61903  1.81512  1.991430   b'13'  \n",
              "  \n",
              "  [500 rows x 129 columns],\n",
              "  'test':          att1      att2      att3      att4      att5      att6      att7  \\\n",
              "  0    2.200280  1.820080  1.366030  0.846295  0.886811  1.322330  1.626250   \n",
              "  1    2.153690  2.028390  1.833580  1.641340  1.420470  1.242790  1.066650   \n",
              "  2    1.036160  0.889494  0.898131  1.000950  0.966536  1.007320  1.093060   \n",
              "  3    1.842690  1.711410  1.518030  1.343270  1.146020  0.935946  0.746994   \n",
              "  4    2.326379  2.348569  2.128169  1.902999  1.754299  1.565309  1.507829   \n",
              "  ..        ...       ...       ...       ...       ...       ...       ...   \n",
              "  620  1.928090  1.737110  1.463660  1.215210  0.948920  0.782923  0.669711   \n",
              "  621  1.927760  1.761410  1.569140  1.373810  1.158100  0.967700  0.778312   \n",
              "  622  1.287250  0.999923  0.717960  0.822148  0.594677  0.303251  0.334923   \n",
              "  623  1.933880  1.827710  1.657990  1.492410  1.332710  1.138780  1.023730   \n",
              "  624  1.718760  1.610230  1.481880  1.374610  1.245880  1.139100  1.009170   \n",
              "  \n",
              "           att8      att9     att10  ...    att120    att121    att122  \\\n",
              "  0    1.121440  0.555643  0.048392  ...  1.278950  1.283890  0.939044   \n",
              "  1    0.940780  0.785536  0.661571  ...  0.657808  0.829616  0.999360   \n",
              "  2    1.172500  1.036870  0.882310  ...  0.549945  0.685654  0.627952   \n",
              "  3    0.616926  0.560006  0.486086  ...  0.764677  0.815949  0.879137   \n",
              "  4    1.254970  0.972944  0.808231  ...  1.097200  1.227920  1.547719   \n",
              "  ..        ...       ...       ...  ...       ...       ...       ...   \n",
              "  620  0.547489  0.406900  0.499377  ...  0.387476  0.476410  0.655162   \n",
              "  621  0.645292  0.459122  0.365264  ...  0.418165  0.531623  0.725657   \n",
              "  622  0.682918  0.462435  0.098170  ...  0.120356  0.487595  0.191567   \n",
              "  623  0.876748  0.749694  0.625895  ...  0.758716  0.900316  0.986537   \n",
              "  624  0.900925  0.790942  0.661032  ...  0.836154  0.932737  1.034840   \n",
              "  \n",
              "         att123    att124    att125    att126    att127    att128  target  \n",
              "  0    0.551711  0.219478  0.719291  1.255270  1.773350  2.188370   b'10'  \n",
              "  1    1.145930  1.301900  1.529360  1.725800  1.922720  2.120270   b'11'  \n",
              "  2    0.765243  0.860108  0.757232  0.803073  0.884178  1.016080    b'8'  \n",
              "  3    1.037530  1.183720  1.312860  1.448120  1.625820  1.822550   b'12'  \n",
              "  4    1.673480  1.818389  1.999299  2.085989  2.182999  2.299839   b'14'  \n",
              "  ..        ...       ...       ...       ...       ...       ...     ...  \n",
              "  620  0.669250  0.817887  1.099230  1.357920  1.638100  1.900690    b'1'  \n",
              "  621  0.895365  1.091130  1.311680  1.508720  1.705110  1.902380    b'9'  \n",
              "  622  0.105113  0.407399  0.757706  0.646935  0.931889  1.274120    b'2'  \n",
              "  623  1.114130  1.283370  1.359680  1.543600  1.706900  1.901550   b'15'  \n",
              "  624  1.151480  1.252020  1.369880  1.471090  1.594080  1.697880    b'7'  \n",
              "  \n",
              "  [625 rows x 129 columns]}}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def join_full_data(data_set_dict):\n",
        "  df_list = []\n",
        "  df_test_list = []\n",
        "  for v, r in data_set_dict.items():\n",
        "    df = pd.DataFrame()\n",
        "    df_test = pd.DataFrame()\n",
        "    #print(v)\n",
        "    r_train = r['train']\n",
        "    r_test = r['test']\n",
        "    r_train1 = r_train.drop(labels='target', axis=1)\n",
        "    r_train2 = r_train[['target']]\n",
        "    r_test1 = r_test.drop(labels='target', axis=1)\n",
        "    r_test2 = r_test[['target']]\n",
        "    df.fillna(df.mean(), inplace=True)\n",
        "    df_test.fillna(df_test.mean(), inplace=True)\n",
        "    print(f'df any: {any(df.isna())}')\n",
        "    print(f'df_test any: {any(df_test.isna())}')\n",
        "    df = df.append(r_train1, ignore_index=True)\n",
        "    df_test = df_test.append(r_train2, ignore_index=True)\n",
        "    df = df.append(r_test1, ignore_index=True)\n",
        "    df_test = df_test.append(r_test2, ignore_index=True)\n",
        "    #print(len(df))\n",
        "    #print(len(r_train))\n",
        "    #print(len(r_test))\n",
        "    \n",
        "    assert len(df) == len(r_test1) + len(r_train1), \"Length error\"\n",
        "    df_list.append(df)\n",
        "    df_test_list.append(df_test)\n",
        "  return df_list, df_test_list\n",
        "\n",
        "\n",
        "joined_full_train_data, joined_full_train_data_target = join_full_data(full_train_sets)\n",
        "joined_full_test_data, joined_full_test_data_target = join_full_data(full_test_sets)\n",
        "joined_partial_train_data = [v.drop(labels='target', axis=1).fillna(v.mean()) for v in partial_train_sets.values()]\n",
        "joined_partial_train_data_target = [v[['target']] for v in partial_train_sets.values()]\n",
        "joined_partial_test_data = [v.drop(labels='target', axis=1).fillna(v.mean()) for v in partial_test_sets.values()]\n",
        "joined_partial_test_data_target = [v[['target']] for v in partial_test_sets.values()]"
      ],
      "metadata": {
        "id": "WeMXCcwU2RtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "932cf156-9e3a-4814-83ac-9be937e9229d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n",
            "df any: False\n",
            "df_test any: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_partial_test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULFXjei1FckW",
        "outputId": "298f1bb6-f680-4d66-9116-bf2e19ff47b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[         att1      att2      att3      att4      att5      att6      att7  \\\n",
              " 0   -0.884255 -0.765115 -0.626403 -0.304591 -0.014302  0.299217  0.512620   \n",
              " 1   -0.785387 -0.655061 -0.467080 -0.154239  0.134839  0.321438  0.653900   \n",
              " 2   -0.972364 -0.838344 -0.561418 -0.236284  0.049412  0.176439  0.480535   \n",
              " 3   -0.682517 -0.541377 -0.357240 -0.071739  0.202066  0.520337  0.628763   \n",
              " 4   -0.942378 -0.818182 -0.565217 -0.334393 -0.052734  0.297825  0.628501   \n",
              " ..        ...       ...       ...       ...       ...       ...       ...   \n",
              " 271 -0.331213 -0.376223 -0.245463 -0.051893  0.161691  0.413482  0.649571   \n",
              " 272 -0.508664 -0.456780 -0.268434 -0.005919  0.232682  0.495963  0.695197   \n",
              " 273 -0.355270 -0.321579 -0.147740  0.061556  0.220212  0.473938  0.420739   \n",
              " 274 -0.456953 -0.371918 -0.188830 -0.015227  0.213377  0.497633  0.773147   \n",
              " 275 -0.348700 -0.293868 -0.142851  0.099887  0.171561  0.416204  0.505821   \n",
              " \n",
              "          att8      att9     att10  ...     att71     att72     att73  \\\n",
              " 0    0.625724  0.894550  1.053017  ... -1.344717 -1.497703 -1.573430   \n",
              " 1    0.858798  1.016743  1.128542  ... -1.339847 -1.400591 -1.436139   \n",
              " 2    0.679617  0.992312  1.058519  ... -1.364141 -1.608421 -1.640499   \n",
              " 3    0.773802  1.099419  1.223326  ... -1.195492 -1.374788 -1.493785   \n",
              " 4    0.896942  1.048016  1.274598  ... -1.189725 -1.376708 -1.488854   \n",
              " ..        ...       ...       ...  ...       ...       ...       ...   \n",
              " 271  0.842033  0.986361  1.167788  ... -1.104583 -1.104583 -1.104583   \n",
              " 272  0.938778  1.150144  1.292290  ... -1.063803 -1.063803 -1.063803   \n",
              " 273  0.530580  0.785306  0.998398  ... -1.118067 -1.118067 -1.118067   \n",
              " 274  1.043223  1.224637  1.349097  ... -1.095296 -1.095296 -1.095296   \n",
              " 275  0.774773  1.043976  1.209277  ... -1.114106 -1.114106 -1.114106   \n",
              " \n",
              "         att74     att75     att76     att77     att78     att79     att80  \n",
              " 0   -1.474905 -1.241796 -1.014918 -0.781760 -0.613538 -0.306603 -0.166550  \n",
              " 1   -1.345779 -1.141555 -1.060367 -0.897301 -0.747584 -0.494699 -0.336926  \n",
              " 2   -1.458569 -1.185203 -0.928913 -0.759410 -0.495612 -0.326797 -0.051992  \n",
              " 3   -1.493988 -1.375257 -1.194475 -0.911856 -0.799136 -0.596014 -0.559966  \n",
              " 4   -1.624198 -1.502584 -1.280325 -0.997454 -0.640286 -0.324204 -0.068927  \n",
              " ..        ...       ...       ...       ...       ...       ...       ...  \n",
              " 271 -1.104583 -1.104583 -1.104583 -1.104583 -1.104583 -1.104583 -1.104583  \n",
              " 272 -1.063803 -1.063803 -1.063803 -1.063803 -1.063803 -1.063803 -1.063803  \n",
              " 273 -1.118067 -1.118067 -1.118067 -1.118067 -1.118067 -1.118067 -1.118067  \n",
              " 274 -1.095296 -1.095296 -1.095296 -1.095296 -1.095296 -1.095296 -1.095296  \n",
              " 275 -1.114106 -1.114106 -1.114106 -1.114106 -1.114106 -1.114106 -1.114106  \n",
              " \n",
              " [276 rows x 80 columns],\n",
              "          att1      att2      att3      att4      att5      att6      att7  \\\n",
              " 0   -0.935797 -0.936068 -0.936108 -0.936148 -0.936212 -0.936260 -0.936292   \n",
              " 1   -0.937594 -0.937397 -0.937569 -0.937586 -0.937620 -0.937852 -0.937973   \n",
              " 2   -0.943812 -0.944012 -0.943921 -0.943766 -0.943657 -0.943830 -0.944167   \n",
              " 3   -0.975728 -0.975410 -0.974955 -0.975177 -0.975559 -0.975760 -0.975834   \n",
              " 4   -0.967652 -0.967889 -0.967833 -0.968097 -0.967902 -0.967527 -0.967902   \n",
              " ..        ...       ...       ...       ...       ...       ...       ...   \n",
              " 495 -0.978310 -0.978200 -0.978360 -0.978557 -0.978649 -0.978571 -0.978498   \n",
              " 496 -0.977837 -0.977804 -0.977913 -0.978108 -0.978185 -0.978209 -0.978229   \n",
              " 497 -0.955360 -0.954432 -0.954541 -0.954647 -0.954458 -0.954445 -0.954899   \n",
              " 498 -0.966969 -0.966609 -0.966717 -0.966883 -0.966810 -0.966643 -0.966610   \n",
              " 499 -0.965067 -0.964507 -0.964234 -0.964422 -0.964440 -0.964296 -0.964554   \n",
              " \n",
              "          att8      att9     att10  ...   att1742   att1743   att1744  \\\n",
              " 0   -0.936228 -0.936028 -0.935972  ... -0.917683 -0.918154 -0.917899   \n",
              " 1   -0.937826 -0.937680 -0.937732  ... -0.919340 -0.919580 -0.920139   \n",
              " 2   -0.944286 -0.944104 -0.943857  ... -0.928731 -0.928786 -0.928886   \n",
              " 3   -0.975813 -0.975516 -0.974987  ... -0.954432 -0.954813 -0.955289   \n",
              " 4   -0.968250 -0.967889 -0.968139  ... -0.948762 -0.949304 -0.949235   \n",
              " ..        ...       ...       ...  ...       ...       ...       ...   \n",
              " 495 -0.978548 -0.978548 -0.978466  ... -0.957066 -0.957432 -0.957744   \n",
              " 496 -0.978169 -0.978075 -0.978003  ... -0.957602 -0.957699 -0.957732   \n",
              " 497 -0.955132 -0.954735 -0.954549  ... -0.934929 -0.934742 -0.935148   \n",
              " 498 -0.966507 -0.966206 -0.965993  ... -0.947200 -0.947044 -0.946968   \n",
              " 499 -0.964733 -0.964322 -0.964149  ... -0.940120 -0.940350 -0.941445   \n",
              " \n",
              "       att1745   att1746   att1747   att1748   att1749   att1750   att1751  \n",
              " 0   -0.917859 -0.918322 -0.918570 -0.919018 -0.919146 -0.919409 -0.919777  \n",
              " 1   -0.919941 -0.920139 -0.920259 -0.920569 -0.920930 -0.920998 -0.921119  \n",
              " 2   -0.929087 -0.928978 -0.929342 -0.930190 -0.929944 -0.930218 -0.929953  \n",
              " 3   -0.955459 -0.955904 -0.956423 -0.956730 -0.956867 -0.957058 -0.957259  \n",
              " 4   -0.949540 -0.950069 -0.950152 -0.949930 -0.950736 -0.950791 -0.950889  \n",
              " ..        ...       ...       ...       ...       ...       ...       ...  \n",
              " 495 -0.957968 -0.958041 -0.958252 -0.958206 -0.958705 -0.958961 -0.959423  \n",
              " 496 -0.957800 -0.957902 -0.958327 -0.958736 -0.959056 -0.959452 -0.959634  \n",
              " 497 -0.935391 -0.935886 -0.936211 -0.937380 -0.936901 -0.937532 -0.936729  \n",
              " 498 -0.947367 -0.947874 -0.947735 -0.948426 -0.948734 -0.949071 -0.949112  \n",
              " 499 -0.941920 -0.942121 -0.942616 -0.943115 -0.943027 -0.942806 -0.942747  \n",
              " \n",
              " [500 rows x 1751 columns],\n",
              "           att1       att2       att3       att4      att5       att6  \\\n",
              " 0     66.74570   66.58170   66.11240   65.56990   65.1745   64.97160   \n",
              " 1     27.38900   26.92350   26.76660   26.71610   26.4541   26.38900   \n",
              " 2     -1.99029   -1.90291   -1.98803   -2.05587   -2.1883   -2.55963   \n",
              " 3    -76.95170  -76.92550  -76.91080  -76.87760  -76.8329  -76.81810   \n",
              " 4    -51.59790  -51.63250  -51.56340  -51.58750  -51.8866  -52.25640   \n",
              " ..         ...        ...        ...        ...       ...        ...   \n",
              " 125  -68.82020  -68.88040  -69.02380  -69.24680  -69.4211  -69.48460   \n",
              " 126  -45.16520  -45.20470  -45.27320  -45.35890  -45.4772  -45.58660   \n",
              " 127   13.98770   13.98290   14.01220   14.04480   14.0610   14.08810   \n",
              " 128   16.25710   15.92960   15.78020   15.71800   15.5209   15.38420   \n",
              " 129 -140.11700 -140.17700 -140.23000 -140.26900 -140.4060 -140.56800   \n",
              " \n",
              "           att7       att8       att9     att10  ...  att351   att352   att353  \\\n",
              " 0     64.73610   64.42130   64.23660   63.8446  ... -57.196 -57.2474 -57.1791   \n",
              " 1     26.37210   26.38780   26.41930   26.4142  ...     NaN      NaN      NaN   \n",
              " 2     -2.72737   -2.19666   -2.02555   -2.6888  ...     NaN      NaN      NaN   \n",
              " 3    -76.81630  -76.81880  -76.82790  -76.8321  ...     NaN      NaN      NaN   \n",
              " 4    -52.37510  -52.29330  -52.42700  -52.5291  ...     NaN      NaN      NaN   \n",
              " ..         ...        ...        ...       ...  ...     ...      ...      ...   \n",
              " 125  -69.53160  -69.55000  -69.59670  -69.6432  ...     NaN      NaN      NaN   \n",
              " 126  -45.63100  -45.70870  -45.79030  -45.9508  ...     NaN      NaN      NaN   \n",
              " 127   14.13650   14.16290   14.24070   14.3286  ...     NaN      NaN      NaN   \n",
              " 128   15.21220   15.09810   14.94500   14.8689  ...     NaN      NaN      NaN   \n",
              " 129 -140.76400 -141.24800 -141.48100 -141.5950  ...     NaN      NaN      NaN   \n",
              " \n",
              "       att354   att355   att356   att357  att358  att359  att360  \n",
              " 0   -57.4624 -57.6517 -57.5435 -57.5329     NaN     NaN     NaN  \n",
              " 1        NaN      NaN      NaN      NaN     NaN     NaN     NaN  \n",
              " 2        NaN      NaN      NaN      NaN     NaN     NaN     NaN  \n",
              " 3        NaN      NaN      NaN      NaN     NaN     NaN     NaN  \n",
              " 4        NaN      NaN      NaN      NaN     NaN     NaN     NaN  \n",
              " ..       ...      ...      ...      ...     ...     ...     ...  \n",
              " 125      NaN      NaN      NaN      NaN     NaN     NaN     NaN  \n",
              " 126      NaN      NaN      NaN      NaN     NaN     NaN     NaN  \n",
              " 127      NaN      NaN      NaN      NaN     NaN     NaN     NaN  \n",
              " 128      NaN      NaN      NaN      NaN     NaN     NaN     NaN  \n",
              " 129      NaN      NaN      NaN      NaN     NaN     NaN     NaN  \n",
              " \n",
              " [130 rows x 360 columns],\n",
              "           att1       att2       att3       att4       att5       att6  \\\n",
              " 0    912.76528  912.84698  912.97074  913.11956  913.27053  913.52253   \n",
              " 1    927.62176  928.63372  929.71597  930.81929  931.84304  932.97148   \n",
              " 2    813.91621  813.95583  813.95799  814.00426  814.06649  814.01247   \n",
              " 3    277.76709  277.80265  277.76932  277.68719  277.75556  277.77561   \n",
              " 4    794.48415  794.79087  795.05626  795.59839  796.04644  797.41076   \n",
              " ..         ...        ...        ...        ...        ...        ...   \n",
              " 311  298.45020  298.31378  298.17639  298.38289  298.28451  298.50919   \n",
              " 312  295.76702  295.45970  295.38695  295.04985  294.75422  294.37121   \n",
              " 313  252.34530  252.21591  252.55971  252.77329  253.04531  253.21259   \n",
              " 314  403.50937  403.51141  403.51948  403.64281  404.62390  407.82251   \n",
              " 315  292.63592  293.19015  294.31066  294.79747  294.64319  294.28139   \n",
              " \n",
              "           att7       att8       att9      att10  ...     att141     att142  \\\n",
              " 0    913.66564  914.06374  914.46600  916.15881  ...  933.91543  933.94974   \n",
              " 1    934.12170  935.29553  936.64085  939.23378  ...  941.39825  941.21745   \n",
              " 2    813.93718  813.99806  814.06667  814.56112  ...  811.80171  811.99991   \n",
              " 3    277.87138  277.90511  277.96173  278.09121  ...  283.01611  282.81633   \n",
              " 4    800.24738  805.85471  814.68666  827.36798  ...  791.24005  791.20637   \n",
              " ..         ...        ...        ...        ...  ...        ...        ...   \n",
              " 311  298.59422  298.58368  298.77324  298.70056  ...  284.61235  286.24605   \n",
              " 312  294.62079  294.30147  294.14446  293.84398  ...  298.56847  298.30538   \n",
              " 313  253.44933  253.29453  253.22132  253.34949  ...  262.45232  254.70434   \n",
              " 314  413.12547  422.77073  436.95157  455.63565  ...  411.03358  410.84884   \n",
              " 315  294.41477  294.56098  294.00862  294.20839  ...  295.45839  295.60149   \n",
              " \n",
              "         att143     att144     att145     att146     att147     att148  \\\n",
              " 0    933.96198  933.94908  933.93521  933.86059  933.75051  933.64351   \n",
              " 1    941.06107  940.86288  940.73887  940.44639  940.23654  939.86973   \n",
              " 2    812.11646  812.19185  812.31013  812.40522  812.46662  812.53985   \n",
              " 3    282.77056  282.56463  282.46805  282.28380  282.12355  282.08575   \n",
              " 4    791.19561  791.11066  791.07077  791.02052  790.98695  790.92370   \n",
              " ..         ...        ...        ...        ...        ...        ...   \n",
              " 311  288.91092  291.79518  295.59542  296.72945  298.88889  299.88924   \n",
              " 312  298.66667  298.48499  298.42188  298.42229  298.15361  298.25767   \n",
              " 313  246.60978  239.07099  235.44120  235.81502  238.19635  241.92164   \n",
              " 314  410.60887  410.47445  410.30760  410.36106  410.24810  410.23502   \n",
              " 315  295.38953  295.49485  295.73487  295.69615  295.63166  295.76453   \n",
              " \n",
              "         att149     att150  \n",
              " 0    933.52530  933.42742  \n",
              " 1    939.57564  939.24957  \n",
              " 2    812.62156  812.59971  \n",
              " 3    282.00883  281.96889  \n",
              " 4    790.90504  790.84162  \n",
              " ..         ...        ...  \n",
              " 311  300.44910  300.75762  \n",
              " 312  298.10794  298.20781  \n",
              " 313  246.37001  250.35282  \n",
              " 314  410.25652  410.23842  \n",
              " 315  295.53411  295.90469  \n",
              " \n",
              " [316 rows x 150 columns],\n",
              "           att1      att2      att3      att4      att5      att6      att7  \\\n",
              " 0    -0.342971 -0.313041 -0.278998 -0.266379 -0.258249 -0.239380 -0.240004   \n",
              " 1    -0.566380 -0.667902 -0.746947 -0.786947 -0.844087 -0.899324 -0.960512   \n",
              " 2    -0.236042 -0.207425 -0.213435 -1.098996  0.321766 -0.578797 -0.837535   \n",
              " 3     1.222500  1.029721  0.371278 -0.090633 -0.203244 -0.346409 -0.415976   \n",
              " 4    -1.022556 -1.060102 -1.071255 -1.116264 -1.167048 -1.194680 -1.218567   \n",
              " ...        ...       ...       ...       ...       ...       ...       ...   \n",
              " 1247 -0.893472 -0.832249 -0.876202 -1.006601 -0.724068 -0.559684 -0.363747   \n",
              " 1248 -1.035570 -1.066416 -1.079312 -0.887277 -1.075031 -1.114812 -1.156933   \n",
              " 1249 -0.128368  0.020477  0.043310  0.168652  0.185692  0.054735  0.036175   \n",
              " 1250 -0.137098 -0.069321 -0.011841  0.034630  0.089795  0.185531  0.242654   \n",
              " 1251 -1.362242 -1.425053 -1.388289 -1.207359 -1.176210 -1.170550 -0.991909   \n",
              " \n",
              "           att8      att9     att10  ...     att75     att76     att77  \\\n",
              " 0    -0.239376 -0.225352 -0.188627  ... -1.041712 -0.982737 -0.903577   \n",
              " 1    -1.018368 -1.062176 -1.111509  ... -1.350740 -1.392645  1.102528   \n",
              " 2    -1.001627 -0.773978 -0.652225  ... -2.035833 -2.242515 -2.432943   \n",
              " 3    -0.216492 -0.336480 -0.787697  ... -0.240086 -0.107627  0.009074   \n",
              " 4    -1.258373 -1.291031 -1.328499  ... -1.063070 -1.035963  0.436232   \n",
              " ...        ...       ...       ...  ...       ...       ...       ...   \n",
              " 1247 -0.139348  0.040146  0.111998  ... -1.690919 -1.499763 -1.354011   \n",
              " 1248 -1.083966 -1.182248 -1.201607  ... -1.158835 -1.171718 -0.183577   \n",
              " 1249  0.013334  0.009052  0.009052  ... -0.273816 -0.166922 -0.010960   \n",
              " 1250  0.268567  0.306743  0.302218  ... -4.874610  0.238762  0.260473   \n",
              " 1251 -0.777524 -0.496186 -0.433884  ... -0.764487 -0.660213 -0.456143   \n",
              " \n",
              "          att78     att79     att80     att81     att82     att83     att84  \n",
              " 0    -0.871315 -0.858517 -0.858942 -0.821831 -0.795969 -0.737660 -0.719023  \n",
              " 1     1.288712  1.184430  1.315856  1.360425  1.433947  1.730128  1.958287  \n",
              " 2    -0.664577 -0.719915 -0.541185 -0.580071 -0.899353 -1.215521 -1.325865  \n",
              " 3     0.123528  0.246111  0.277475  0.323939  0.408914  0.379662  0.417792  \n",
              " 4     0.837282  1.408443  1.886734  1.319802  0.575913  0.896932  1.219999  \n",
              " ...        ...       ...       ...       ...       ...       ...       ...  \n",
              " 1247 -1.158364 -0.889937 -0.655344 -0.511019 -0.306678 -0.237454 -0.133746  \n",
              " 1248  0.144976  0.397248  0.710431  0.986983  0.980335  1.043356  1.261406  \n",
              " 1249 -0.013829 -0.190731 -0.197938 -0.164731 -0.114983 -0.153488 -0.182519  \n",
              " 1250  0.263389  0.268567  0.251725  0.238762  0.243949  0.257944  0.267273  \n",
              " 1251 -0.235163 -0.069872  0.103917  0.217779  0.274307  0.314930  0.365240  \n",
              " \n",
              " [1252 rows x 84 columns],\n",
              "           att1      att2      att3      att4      att5      att6      att7  \\\n",
              " 0     3.440239  3.610072  3.779904  3.925655  4.023241  4.028724  3.911685   \n",
              " 1     3.595452  3.788143  3.948458  4.048351  4.018263  3.878024  3.656847   \n",
              " 2     3.183092  3.183092  3.183092  3.169367  3.035522  2.762388  2.486258   \n",
              " 3     3.637380  3.488408  3.325608  3.144302  2.941904  2.717869  2.469582   \n",
              " 4     3.595043  3.483953  3.312021  3.079245  2.805975  2.519111  2.240249   \n",
              " ...        ...       ...       ...       ...       ...       ...       ...   \n",
              " 1960  4.497927  4.557191  4.532647  4.460214  4.347074  4.184846  3.969641   \n",
              " 1961  3.576181  3.516520  3.425286  3.305476  3.161569  2.999246  2.824782   \n",
              " 1962  3.661288  3.593366  3.488450  3.324273  3.081158  2.764845  2.404665   \n",
              " 1963  4.360352  4.457065  4.460212  4.394990  4.283563  4.139738  3.960044   \n",
              " 1964  3.304410  3.454126  3.587271  3.696634  3.775001  3.769543  3.656086   \n",
              " \n",
              "           att8      att9     att10  ...    att741    att742    att743  \\\n",
              " 0     3.663677  3.325271  2.934478  ...  0.987835  1.116123  1.267924   \n",
              " 1     3.365468  3.027129  2.651964  ...  0.975579  1.092261  1.226693   \n",
              " 2     2.246853  2.043540  1.831785  ...  2.551446  2.846605  3.078607   \n",
              " 3     2.217224  1.964409  1.701946  ...  2.824872  3.062400  3.227905   \n",
              " 4     2.000294  1.786236  1.574553  ...  2.459162  2.770674  3.044625   \n",
              " ...        ...       ...       ...  ...       ...       ...       ...   \n",
              " 1960  3.728994  3.538632  3.369221  ...  1.916959  2.244107  2.536834   \n",
              " 1961  2.623249  2.406174  2.180547  ...  2.236872  2.545989  2.818188   \n",
              " 1962  2.016794  1.625465  1.229755  ...  2.229856  2.571576  2.904734   \n",
              " 1963  3.735674  3.505415  3.287371  ...  1.733028  2.082954  2.436369   \n",
              " 1964  3.437361  3.115609  2.736641  ...  1.216480  1.323309  1.448754   \n",
              " \n",
              "         att744    att745    att746    att747    att748    att749    att750  \n",
              " 0     1.454651  1.686861  1.971742  2.280990  2.582914  2.879207  3.105651  \n",
              " 1     1.416262  1.686810  2.033408  2.422035  2.799283  3.109615  3.339009  \n",
              " 2     3.175019  3.183092  3.183092  3.183092  3.183092  3.183092  3.183092  \n",
              " 3     3.329027  3.390445  3.476115  3.580550  3.671204  3.729294  3.752816  \n",
              " 4     3.244587  3.384025  3.504484  3.588891  3.638997  3.662321  3.653433  \n",
              " ...        ...       ...       ...       ...       ...       ...       ...  \n",
              " 1960  2.779277  2.970837  3.149826  3.363534  3.628126  3.912173  4.143841  \n",
              " 1961  3.028644  3.177798  3.285670  3.378401  3.472561  3.568436  3.642560  \n",
              " 1962  3.153186  3.313946  3.407591  3.463455  3.502660  3.524065  3.493679  \n",
              " 1963  2.771862  3.049360  3.273419  3.477618  3.696343  3.931775  4.123443  \n",
              " 1964  1.605488  1.811444  2.088262  2.428632  2.787131  3.113269  3.356557  \n",
              " \n",
              " [1965 rows x 750 columns],\n",
              "          att1      att2      att3      att4      att5      att6      att7  \\\n",
              " 0   -0.274747 -0.274747  2.206837  3.447629  2.206837  0.966045 -0.274747   \n",
              " 1    1.652835  2.497350  2.497350  2.497350  1.230578 -0.036193 -0.669579   \n",
              " 2    0.174510  1.326931  1.787900  1.787900  0.865963  0.174510 -0.747428   \n",
              " 3    0.366404  0.984434  3.456556  3.147541  1.602465  0.057389 -0.251627   \n",
              " 4    0.049486  0.742297  1.204171  2.358856  1.204171  0.280423 -1.105198   \n",
              " ..        ...       ...       ...       ...       ...       ...       ...   \n",
              " 596  1.451872  2.021765  2.021765  1.641836  0.692014 -0.257809 -1.207632   \n",
              " 597  0.548904  0.018928 -0.246061  1.873846  2.138834  1.078881  0.018928   \n",
              " 598  1.275521  1.275521  2.351263  1.705818  1.275521  0.414929 -0.445664   \n",
              " 599 -0.484071 -0.176026  1.056156  1.980292  0.132019 -1.408207 -1.100162   \n",
              " 600  1.320462  1.915520  2.510578  2.312225  1.717167  0.130346 -0.663065   \n",
              " \n",
              "          att8      att9     att10  ...     att61     att62     att63  \\\n",
              " 0   -0.895143 -0.895143  0.345649  ...  0.035451 -0.274747 -0.584945   \n",
              " 1   -1.302965 -1.514094 -1.514094  ... -0.036193 -0.036193 -0.036193   \n",
              " 2   -1.208397 -1.669365 -1.208397  ... -0.055975  0.404994  0.404994   \n",
              " 3   -0.869657 -1.178672 -0.251627  ...  0.057389  0.057389 -0.251627   \n",
              " 4   -1.336135 -0.643324 -0.412387  ...  0.280423 -0.643324 -1.105198   \n",
              " ..        ...       ...       ...  ...       ...       ...       ...   \n",
              " 596 -1.587561 -1.207632 -0.637738  ... -0.067844  0.312085  0.692014   \n",
              " 597 -1.306014 -1.571002 -0.246061  ...  0.018928  0.283916  0.018928   \n",
              " 598 -1.091109 -0.875961 -0.445664  ...  0.414929  0.630077  0.414929   \n",
              " 599 -0.484071 -0.176026 -0.792117  ...  0.132019  0.440065  0.440065   \n",
              " 600 -1.258123 -1.654828 -1.258123  ...  0.328699  0.328699  0.328699   \n",
              " \n",
              "         att64     att65     att66     att67     att68     att69     att70  \n",
              " 0   -0.274747 -0.274747  0.035451  0.035451  0.035451  0.035451 -0.584945  \n",
              " 1   -0.036193 -0.247322 -0.247322 -0.458451 -0.247322 -0.036193  0.174935  \n",
              " 2    0.635478  0.635478  0.404994  0.174510  0.174510 -0.055975  0.174510  \n",
              " 3   -0.560642 -0.251627 -0.251627  0.366404  0.366404  0.057389 -0.251627  \n",
              " 4   -0.874261 -0.181450  0.280423  0.511360  0.742297  0.742297  0.280423  \n",
              " ..        ...       ...       ...       ...       ...       ...       ...  \n",
              " 596  0.692014  0.502049  0.312085  0.312085  0.502049  0.692014  0.502049  \n",
              " 597 -0.246061  0.283916  0.548904  1.343869  0.813893  0.813893  0.813893  \n",
              " 598  0.199780 -0.015368  0.199780  0.414929  0.630077  0.845225  1.060373  \n",
              " 599  0.748110  0.440065  0.440065  0.440065  0.440065  0.132019  0.132019  \n",
              " 600 -0.068007 -0.464712 -0.266359 -0.266359 -0.068007 -0.068007 -0.068007  \n",
              " \n",
              " [601 rows x 70 columns]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = list(full_train_sets['ACSF1']['test'].columns)\n",
        "len(cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UZBRV4tI5ro",
        "outputId": "f01a71a2-3aa4-4cf1-f40c-1fe027e33e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1461"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#joined_partial_test_data[0][joined_partial_test_data[0].isna()]\n",
        "any(joined_full_test_data[0].isna())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2hHuNP6Q_Mb",
        "outputId": "4d22e4ba-ac83-415d-eefa-a45589d850b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts_train_length = [len(df.columns) for df in joined_full_train_data]\n",
        "ts_test_length = [len(df.columns) for df in joined_full_test_data]\n",
        "max_ts_length = max([max(ts_train_length), max(ts_test_length)])"
      ],
      "metadata": {
        "id": "kuizzjxHhpES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_ts_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWEvC1hZvY-z",
        "outputId": "33ebf9b6-0753-49a8-aa6f-d07512a286e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2844"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def padding_ts_data(data, max_size=3000):\n",
        "  #re = data.apply(lambda x: x.append(pd.Series([0] * (max_size - len(x)))) if len(x) < max_size else x, axis=1)\n",
        "  return data\n",
        "\n",
        "\n",
        "def standardize_ts(data):\n",
        "  scaler = StandardScaler().fit(data)\n",
        "  return scaler.transform(data)"
      ],
      "metadata": {
        "id": "SiqpsAsux3wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dat = (joined_full_train_data[0])"
      ],
      "metadata": {
        "id": "0Vye83SLn5Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_size = 3000\n",
        "uu = dat.apply(lambda x: x.append(pd.Series([0] * (max_size - len(x)))) if len(x) < max_size else x, axis=1)\n",
        "uu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YXt8Hvp_n5T_",
        "outputId": "ad0b285b-50ff-4312-8570-0e399b29f13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         att1      att2      att3      att4      att5      att6      att7  \\\n",
              "0   -0.584754 -0.584754  1.730991 -0.584754 -0.584754 -0.584754  1.729917   \n",
              "1   -0.591434 -0.511104  1.726820 -0.580422 -0.591434 -0.511104  1.727921   \n",
              "2   -0.577945 -0.577945  1.730793 -0.577945 -0.578946 -0.564882  1.731094   \n",
              "3   -0.588925 -0.538088  1.735718 -0.588716 -0.589962 -0.523551  1.735619   \n",
              "4   -0.596633 -0.532188  1.718067 -0.592117 -0.596633 -0.532188  1.715241   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "195 -0.865824  0.116534  1.665577 -0.664466 -0.668138 -0.668138  1.667320   \n",
              "196 -0.631937 -0.631937  1.612754 -0.631937 -0.631937 -0.631937  1.602539   \n",
              "197 -0.997077  0.108756  1.585963 -0.695920 -0.996043  0.106678  1.585752   \n",
              "198 -0.891590 -0.752940  1.424231 -0.752324 -0.891590 -0.751933  1.421933   \n",
              "199 -0.845868 -0.650711  1.561223 -0.650859 -0.845868 -0.650711  1.561076   \n",
              "\n",
              "         att8      att9     att10  ...  1530  1531  1532  1533  1534  1535  \\\n",
              "0   -0.584754 -0.584754 -0.584754  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "1   -0.580422 -0.591434 -0.511104  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "2   -0.577829 -0.580956 -0.548788  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "3   -0.588646 -0.588925 -0.524598  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "4   -0.592117 -0.595605 -0.532188  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "..        ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
              "195 -0.668138 -0.668138 -0.668138  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "196 -0.631937 -0.631937 -0.631937  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "197 -0.695931 -0.994998  0.107722  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "198 -0.752324 -0.892596 -0.747885  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "199 -0.650859 -0.846880 -0.650711  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
              "\n",
              "     1536  1537  1538  1539  \n",
              "0     0.0   0.0   0.0   0.0  \n",
              "1     0.0   0.0   0.0   0.0  \n",
              "2     0.0   0.0   0.0   0.0  \n",
              "3     0.0   0.0   0.0   0.0  \n",
              "4     0.0   0.0   0.0   0.0  \n",
              "..    ...   ...   ...   ...  \n",
              "195   0.0   0.0   0.0   0.0  \n",
              "196   0.0   0.0   0.0   0.0  \n",
              "197   0.0   0.0   0.0   0.0  \n",
              "198   0.0   0.0   0.0   0.0  \n",
              "199   0.0   0.0   0.0   0.0  \n",
              "\n",
              "[200 rows x 3000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c05e13bc-b278-42ed-97cc-f4f28cca2dd4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>att1</th>\n",
              "      <th>att2</th>\n",
              "      <th>att3</th>\n",
              "      <th>att4</th>\n",
              "      <th>att5</th>\n",
              "      <th>att6</th>\n",
              "      <th>att7</th>\n",
              "      <th>att8</th>\n",
              "      <th>att9</th>\n",
              "      <th>att10</th>\n",
              "      <th>...</th>\n",
              "      <th>1530</th>\n",
              "      <th>1531</th>\n",
              "      <th>1532</th>\n",
              "      <th>1533</th>\n",
              "      <th>1534</th>\n",
              "      <th>1535</th>\n",
              "      <th>1536</th>\n",
              "      <th>1537</th>\n",
              "      <th>1538</th>\n",
              "      <th>1539</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>1.730991</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>1.729917</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>-0.584754</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.591434</td>\n",
              "      <td>-0.511104</td>\n",
              "      <td>1.726820</td>\n",
              "      <td>-0.580422</td>\n",
              "      <td>-0.591434</td>\n",
              "      <td>-0.511104</td>\n",
              "      <td>1.727921</td>\n",
              "      <td>-0.580422</td>\n",
              "      <td>-0.591434</td>\n",
              "      <td>-0.511104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.577945</td>\n",
              "      <td>-0.577945</td>\n",
              "      <td>1.730793</td>\n",
              "      <td>-0.577945</td>\n",
              "      <td>-0.578946</td>\n",
              "      <td>-0.564882</td>\n",
              "      <td>1.731094</td>\n",
              "      <td>-0.577829</td>\n",
              "      <td>-0.580956</td>\n",
              "      <td>-0.548788</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.588925</td>\n",
              "      <td>-0.538088</td>\n",
              "      <td>1.735718</td>\n",
              "      <td>-0.588716</td>\n",
              "      <td>-0.589962</td>\n",
              "      <td>-0.523551</td>\n",
              "      <td>1.735619</td>\n",
              "      <td>-0.588646</td>\n",
              "      <td>-0.588925</td>\n",
              "      <td>-0.524598</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.596633</td>\n",
              "      <td>-0.532188</td>\n",
              "      <td>1.718067</td>\n",
              "      <td>-0.592117</td>\n",
              "      <td>-0.596633</td>\n",
              "      <td>-0.532188</td>\n",
              "      <td>1.715241</td>\n",
              "      <td>-0.592117</td>\n",
              "      <td>-0.595605</td>\n",
              "      <td>-0.532188</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>-0.865824</td>\n",
              "      <td>0.116534</td>\n",
              "      <td>1.665577</td>\n",
              "      <td>-0.664466</td>\n",
              "      <td>-0.668138</td>\n",
              "      <td>-0.668138</td>\n",
              "      <td>1.667320</td>\n",
              "      <td>-0.668138</td>\n",
              "      <td>-0.668138</td>\n",
              "      <td>-0.668138</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>-0.631937</td>\n",
              "      <td>-0.631937</td>\n",
              "      <td>1.612754</td>\n",
              "      <td>-0.631937</td>\n",
              "      <td>-0.631937</td>\n",
              "      <td>-0.631937</td>\n",
              "      <td>1.602539</td>\n",
              "      <td>-0.631937</td>\n",
              "      <td>-0.631937</td>\n",
              "      <td>-0.631937</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>-0.997077</td>\n",
              "      <td>0.108756</td>\n",
              "      <td>1.585963</td>\n",
              "      <td>-0.695920</td>\n",
              "      <td>-0.996043</td>\n",
              "      <td>0.106678</td>\n",
              "      <td>1.585752</td>\n",
              "      <td>-0.695931</td>\n",
              "      <td>-0.994998</td>\n",
              "      <td>0.107722</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>-0.891590</td>\n",
              "      <td>-0.752940</td>\n",
              "      <td>1.424231</td>\n",
              "      <td>-0.752324</td>\n",
              "      <td>-0.891590</td>\n",
              "      <td>-0.751933</td>\n",
              "      <td>1.421933</td>\n",
              "      <td>-0.752324</td>\n",
              "      <td>-0.892596</td>\n",
              "      <td>-0.747885</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>-0.845868</td>\n",
              "      <td>-0.650711</td>\n",
              "      <td>1.561223</td>\n",
              "      <td>-0.650859</td>\n",
              "      <td>-0.845868</td>\n",
              "      <td>-0.650711</td>\n",
              "      <td>1.561076</td>\n",
              "      <td>-0.650859</td>\n",
              "      <td>-0.846880</td>\n",
              "      <td>-0.650711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 3000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c05e13bc-b278-42ed-97cc-f4f28cca2dd4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c05e13bc-b278-42ed-97cc-f4f28cca2dd4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c05e13bc-b278-42ed-97cc-f4f28cca2dd4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "standardize_ts(uu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhnuA9aNomOU",
        "outputId": "42e94612-e6ae-4851-a0f4-eab71acafc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.35505096, -0.47773131,  0.67345937, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.32759412, -0.32748712,  0.66092828, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.38303305, -0.46384227,  0.67286486, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [-1.33957   ,  0.93701898,  0.23777877, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.90602436, -0.82082834, -0.24808629, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.71811241, -0.61228389,  0.16345529, ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding padding to all elements and scaling them\n",
        "joined_full_train_data_padded = list(map(padding_ts_data, joined_full_train_data))\n",
        "joined_full_test_data_padded = list(map(padding_ts_data, joined_full_test_data))\n",
        "joined_partial_train_data_padded = list(map(padding_ts_data, joined_partial_train_data))\n",
        "joined_partial_test_data_padded = list(map(padding_ts_data, joined_partial_test_data))\n",
        "\n",
        "joined_full_train_data_padded = list(map(standardize_ts, joined_full_train_data_padded))\n",
        "joined_full_test_data_padded = list(map(standardize_ts, joined_full_test_data_padded))\n",
        "joined_partial_train_data_padded = list(map(standardize_ts, joined_partial_train_data_padded))\n",
        "joined_partial_test_data_padded = list(map(standardize_ts, joined_partial_test_data_padded))\n",
        "\n",
        "\"\"\"joined_full_train_data = join_full_data(full_train_sets)\n",
        "joined_full_test_data = join_full_data(full_test_sets)\n",
        "joined_partial_train_data = [v.drop(labels='target', axis=1) for v in partial_train_sets.values()]\n",
        "joined_partial_test_data = [v.drop(labels='target', axis=1) for v in partial_test_sets.values()]\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "pZBJzQJJpSN9",
        "outputId": "4e6c34ec-b8aa-4c81-c907-2816dc9d23a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:990: RuntimeWarning: invalid value encountered in true_divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:1020: RuntimeWarning: invalid value encountered in true_divide\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:990: RuntimeWarning: invalid value encountered in true_divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:1020: RuntimeWarning: invalid value encountered in true_divide\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:990: RuntimeWarning: invalid value encountered in true_divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:1020: RuntimeWarning: invalid value encountered in true_divide\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:990: RuntimeWarning: invalid value encountered in true_divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/extmath.py:1020: RuntimeWarning: invalid value encountered in true_divide\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"joined_full_train_data = join_full_data(full_train_sets)\\njoined_full_test_data = join_full_data(full_test_sets)\\njoined_partial_train_data = [v.drop(labels='target', axis=1) for v in partial_train_sets.values()]\\njoined_partial_test_data = [v.drop(labels='target', axis=1) for v in partial_test_sets.values()]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_full_train_data_padded[0][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waJX3am1rK21",
        "outputId": "d75012fd-7d56-4af5-dace-f674c2c2c460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.35505096, -0.47773131,  0.67345937, ..., -0.63686518,\n",
              "         0.67685741,  0.41179997],\n",
              "       [ 0.32759412, -0.32748712,  0.66092828, ..., -0.64214333,\n",
              "         0.66083579,  0.44001419],\n",
              "       [ 0.38303305, -0.46384227,  0.67286486, ..., -0.56538792,\n",
              "         0.68287303,  0.46101128],\n",
              "       [ 0.33790554, -0.38253292,  0.68766076, ..., -0.63160292,\n",
              "         0.70974116,  0.38261301],\n",
              "       [ 0.30622722, -0.37049785,  0.6346353 , ..., -0.62831604,\n",
              "         0.70852036,  0.35775137]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting data to dataframes and saving it\n",
        "\n",
        "\n",
        "joined_full_train_data_padded_dfs = list(map(pd.DataFrame, joined_full_train_data_padded))\n",
        "joined_full_test_data_padded_dfs = list(map(pd.DataFrame, joined_full_test_data_padded))\n",
        "joined_partial_train_data_padded_dfs = list(map(pd.DataFrame, joined_partial_train_data_padded))\n",
        "joined_partial_test_data_padded_dfs = list(map(pd.DataFrame, joined_partial_test_data_padded))\n",
        "\n"
      ],
      "metadata": {
        "id": "Se8_MsTFv9Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def save_dataframes(df_list, df_target_list, list_of_names, main_folder, file_types='train'):\n",
        "  if not os.path.exists(main_folder):\n",
        "    os.mkdir(main_folder)\n",
        "  fld = f'{main_folder}/{file_types}'\n",
        "  if file_types == 'train' and not os.path.exists(fld):\n",
        "    os.mkdir(fld)\n",
        "    os.mkdir(f'{fld}_target')\n",
        "  if file_types == 'test' and not os.path.exists(fld):\n",
        "    os.mkdir(fld)\n",
        "    os.mkdir(f'{fld}_target')\n",
        "  for df, f_name, df_target in zip(df_list, list_of_names, df_target_list):\n",
        "    path_to_file = f'{fld}/{f_name}.csv'\n",
        "    path_to_file_target = f'{main_folder}/{file_types}_target/{f_name}_target.csv'\n",
        "    df_target.to_csv(path_to_file_target, index=False)\n",
        "    df.to_csv(path_to_file, index=False)"
      ],
      "metadata": {
        "id": "E3UCqc1lwyTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_folder = \"processed_data\"\n",
        "# full_test_sets, partial_test_sets, full_train_sets, partial_train_sets\n",
        "save_dataframes(joined_full_train_data_padded_dfs, joined_full_train_data_target, list(full_train_sets.keys()), main_folder, file_types='train')\n",
        "save_dataframes(joined_full_test_data_padded_dfs, joined_full_test_data_target, list(full_test_sets.keys()), main_folder, file_types='test')\n",
        "save_dataframes(joined_partial_train_data_padded_dfs, joined_partial_train_data_target, list(partial_train_sets.keys()), main_folder, file_types='train') \n",
        "save_dataframes(joined_partial_test_data_padded_dfs, joined_partial_test_data_target, list(partial_test_sets.keys()), main_folder, file_types='test')"
      ],
      "metadata": {
        "id": "_UrQSkzX10hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wpaqZCud2b1Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}